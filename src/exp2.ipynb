{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T08:51:48.237307Z",
     "start_time": "2025-11-13T08:51:48.232398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "stdout_handler = logging.StreamHandler(sys.stdout)\n",
    "def setup_logging(log_dir:Path):\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "    log_dir.mkdir(parents=True, exist_ok=True)\n",
    "    log_filename = log_dir/f\"{timestamp}.log\"\n",
    "\n",
    "    file_handler = logging.FileHandler(log_filename)\n",
    "\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[stdout_handler, file_handler]\n",
    "    )\n",
    "\n",
    "def flush_logger():\n",
    "    stdout_handler.flush()\n",
    "\n",
    "setup_logging(Path('../logs'))\n",
    "logger = logging.getLogger(__name__)"
   ],
   "id": "e5ac7a92777dcdbf",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-13T08:51:49.632389Z",
     "start_time": "2025-11-13T08:51:48.243978Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from config import FieldConfig, ExperimentConfig\n",
    "from pathlib import Path\n",
    "DATA_PATH = Path('C:/Work/Data/proc/')\n",
    "field_config = FieldConfig()\n",
    "\n",
    "df = pd.read_csv(DATA_PATH/'rec_data2.csv')\n",
    "\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_values)\n",
    "\n",
    "df_cleaned = df.dropna(subset=[field_config.date, field_config.amount, field_config.text, field_config.label])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "id                    0\n",
      "accountId             0\n",
      "date                  0\n",
      "amount                0\n",
      "bankRawDescription    0\n",
      "isRecurring           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T08:51:49.843680Z",
     "start_time": "2025-11-13T08:51:49.690908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from feature_processor import FeatProcParams\n",
    "from config import *\n",
    "\n",
    "feat_params = FeatProcParams(n_bins=20, k_top=50)\n",
    "feat_params_off = FeatProcParams.NOP()\n",
    "\n",
    "exp_config = ExperimentConfig()\n",
    "\n",
    "fracs = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]"
   ],
   "id": "64ad44e449b7478f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T08:51:51.586552Z",
     "start_time": "2025-11-13T08:51:49.853335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from runner import ExpRunner\n",
    "from config import EmbModel\n",
    "from embedder import EmbeddingService\n",
    "\n",
    "runner1 = ExpRunner.create(\n",
    "    exp_params=exp_config,\n",
    "    full_df=df_cleaned,\n",
    "    emb_params=EmbeddingService.Params(model_name=EmbModel.ALBERT),\n",
    "    feat_proc_params=feat_params,\n",
    "    field_config=FieldConfig()\n",
    ")"
   ],
   "id": "d651a17edece86d3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoav.haimovitch\\PycharmProjects\\PythonProject\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T08:58:17.545099Z",
     "start_time": "2025-11-13T08:51:51.610467Z"
    }
   },
   "cell_type": "code",
   "source": "results = runner1.run_torch(fracs)",
   "id": "97b17b877b9520a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-13 10:51:51,617 - INFO - Splitting 189987 rows by group 'accountId'...\n",
      "2025-11-13 10:51:51,688 - INFO - Train accounts: 984, Test accounts: 246\n",
      "2025-11-13 10:51:51,689 - INFO - SUCCESS: No account overlap between train and test sets.\n",
      "2025-11-13 10:51:51,696 - INFO - Split complete. Train: len=156523 accounts=984, Test: len=33464 accounts=246.\n",
      "2025-11-13 10:51:51,700 - INFO - Preparing to create 7 training set fractions...\n",
      "2025-11-13 10:51:51,713 - INFO - Yielding 10% split: 98 accounts, 16704 rows\n",
      "2025-11-13 10:51:51,714 - INFO - Creating new EmbeddingService(model_name=albert-base-v2)\n",
      "2025-11-13 10:51:51,715 - INFO - Loading embedding model: albert-base-v2...\n",
      "2025-11-13 10:51:53,367 - INFO - Model albert-base-v2 loaded onto cpu. Cache at cache/albert-base-v2\n",
      "2025-11-13 10:51:53,368 - INFO - Embedding 16704 train texts...\n",
      "2025-11-13 10:51:53,504 - INFO - len(text_list)=16704 len(unique_texts)=10952 len(texts_to_embed)=0\n",
      "2025-11-13 10:51:53,764 - INFO - Embedding 33464 test texts...\n",
      "2025-11-13 10:51:54,032 - INFO - len(text_list)=33464 len(unique_texts)=20665 len(texts_to_embed)=0\n",
      "2025-11-13 10:51:54,664 - INFO - Fitting processor on 16704 rows...\n",
      "2025-11-13 10:51:54,665 - INFO - Fitting categorical amount features...\n",
      "2025-11-13 10:51:54,671 - INFO - Fit complete. Found 50 magic numbers.\n",
      "2025-11-13 10:51:54,671 - INFO - Created 20 fallback bins.\n",
      "2025-11-13 10:51:54,672 - INFO - Total Amount Vocabulary size: 72\n",
      "2025-11-13 10:51:54,672 - INFO - Fit complete. Found 50 magic numbers.\n",
      "2025-11-13 10:51:54,673 - INFO - Transforming 16704 rows...\n",
      "2025-11-13 10:51:54,731 - INFO - Transform complete.\n",
      "2025-11-13 10:51:54,732 - INFO - Transforming 33464 rows...\n",
      "2025-11-13 10:51:54,844 - INFO - Transform complete.\n",
      "Model Init: use_text=True, use_continuous=True, use_categorical=True\n",
      "Total input dim to MLP: 889\n",
      "2025-11-13 10:51:54,875 - INFO - Starting PyTorch training on cpu for 10 epochs...\n",
      "2025-11-13 10:51:55,908 - INFO - Epoch 1/10 [1.03s] | Train Loss: 0.5377 | Test Loss: 0.3997 | F1: 0.6518 | ROC-AUC: 0.8734\n",
      "2025-11-13 10:51:56,952 - INFO - Epoch 2/10 [1.04s] | Train Loss: 0.3826 | Test Loss: 0.3011 | F1: 0.6838 | ROC-AUC: 0.9044\n",
      "2025-11-13 10:51:57,953 - INFO - Epoch 3/10 [1.00s] | Train Loss: 0.3059 | Test Loss: 0.3104 | F1: 0.5899 | ROC-AUC: 0.9051\n",
      "2025-11-13 10:51:58,941 - INFO - Epoch 4/10 [0.99s] | Train Loss: 0.2715 | Test Loss: 0.3225 | F1: 0.5667 | ROC-AUC: 0.9124\n",
      "2025-11-13 10:52:00,214 - INFO - Epoch 5/10 [1.27s] | Train Loss: 0.2489 | Test Loss: 0.3105 | F1: 0.5576 | ROC-AUC: 0.9241\n",
      "2025-11-13 10:52:01,391 - INFO - Epoch 6/10 [1.18s] | Train Loss: 0.2400 | Test Loss: 0.3423 | F1: 0.5638 | ROC-AUC: 0.8724\n",
      "2025-11-13 10:52:02,504 - INFO - Epoch 7/10 [1.11s] | Train Loss: 0.2263 | Test Loss: 0.3031 | F1: 0.6575 | ROC-AUC: 0.9106\n",
      "2025-11-13 10:52:03,717 - INFO - Epoch 8/10 [1.21s] | Train Loss: 0.2220 | Test Loss: 0.3622 | F1: 0.4462 | ROC-AUC: 0.9115\n",
      "2025-11-13 10:52:04,887 - INFO - Epoch 9/10 [1.17s] | Train Loss: 0.2142 | Test Loss: 0.3092 | F1: 0.5703 | ROC-AUC: 0.9275\n",
      "2025-11-13 10:52:06,013 - INFO - Epoch 10/10 [1.13s] | Train Loss: 0.2071 | Test Loss: 0.2622 | F1: 0.7149 | ROC-AUC: 0.9257\n",
      "2025-11-13 10:52:06,014 - INFO - Training complete.\n",
      "2025-11-13 10:52:06,017 - INFO - {'loss': 0.262, 'accuracy': 0.902, 'f1': 0.715, 'roc_auc': 0.926, 'embedder.model_name': 'albert-base-v2', 'train_frac': 0.1, 'train_size': 16704, 'test_size': 33464, 'train_accounts': 98, 'test_accounts': 246}\n",
      "2025-11-13 10:52:06,024 - INFO - Yielding 20% split: 196 accounts, 29736 rows\n",
      "2025-11-13 10:52:06,025 - INFO - Embedding 29736 train texts...\n",
      "2025-11-13 10:52:06,512 - INFO - len(text_list)=29736 len(unique_texts)=19347 len(texts_to_embed)=0\n",
      "2025-11-13 10:52:06,978 - INFO - Embedding 33464 test texts...\n",
      "2025-11-13 10:52:07,243 - INFO - len(text_list)=33464 len(unique_texts)=20665 len(texts_to_embed)=0\n",
      "2025-11-13 10:52:07,909 - INFO - Fitting processor on 29736 rows...\n",
      "2025-11-13 10:52:07,909 - INFO - Fitting categorical amount features...\n",
      "2025-11-13 10:52:07,918 - INFO - Fit complete. Found 50 magic numbers.\n",
      "2025-11-13 10:52:07,919 - INFO - Created 20 fallback bins.\n",
      "2025-11-13 10:52:07,920 - INFO - Total Amount Vocabulary size: 72\n",
      "2025-11-13 10:52:07,920 - INFO - Fit complete. Found 50 magic numbers.\n",
      "2025-11-13 10:52:07,921 - INFO - Transforming 29736 rows...\n",
      "2025-11-13 10:52:08,021 - INFO - Transform complete.\n",
      "2025-11-13 10:52:08,022 - INFO - Transforming 33464 rows...\n",
      "2025-11-13 10:52:08,130 - INFO - Transform complete.\n",
      "Model Init: use_text=True, use_continuous=True, use_categorical=True\n",
      "Total input dim to MLP: 889\n",
      "2025-11-13 10:52:08,164 - INFO - Starting PyTorch training on cpu for 10 epochs...\n",
      "2025-11-13 10:52:09,808 - INFO - Epoch 1/10 [1.64s] | Train Loss: 0.4976 | Test Loss: 0.3455 | F1: 0.6329 | ROC-AUC: 0.8531\n",
      "2025-11-13 10:52:11,279 - INFO - Epoch 2/10 [1.47s] | Train Loss: 0.3158 | Test Loss: 0.2901 | F1: 0.7139 | ROC-AUC: 0.9119\n",
      "2025-11-13 10:52:12,871 - INFO - Epoch 3/10 [1.59s] | Train Loss: 0.2709 | Test Loss: 0.2665 | F1: 0.7078 | ROC-AUC: 0.9202\n",
      "2025-11-13 10:52:14,293 - INFO - Epoch 4/10 [1.42s] | Train Loss: 0.2500 | Test Loss: 0.2925 | F1: 0.5827 | ROC-AUC: 0.9290\n",
      "2025-11-13 10:52:15,818 - INFO - Epoch 5/10 [1.52s] | Train Loss: 0.2330 | Test Loss: 0.3143 | F1: 0.7249 | ROC-AUC: 0.9137\n",
      "2025-11-13 10:52:17,417 - INFO - Epoch 6/10 [1.60s] | Train Loss: 0.2237 | Test Loss: 0.2475 | F1: 0.7185 | ROC-AUC: 0.9316\n",
      "2025-11-13 10:52:19,185 - INFO - Epoch 7/10 [1.77s] | Train Loss: 0.2163 | Test Loss: 0.2440 | F1: 0.7372 | ROC-AUC: 0.9372\n",
      "2025-11-13 10:52:20,933 - INFO - Epoch 8/10 [1.75s] | Train Loss: 0.2117 | Test Loss: 0.3328 | F1: 0.5090 | ROC-AUC: 0.9074\n",
      "2025-11-13 10:52:22,590 - INFO - Epoch 9/10 [1.66s] | Train Loss: 0.2104 | Test Loss: 0.2408 | F1: 0.7559 | ROC-AUC: 0.9336\n",
      "2025-11-13 10:52:24,348 - INFO - Epoch 10/10 [1.76s] | Train Loss: 0.2008 | Test Loss: 0.2404 | F1: 0.7819 | ROC-AUC: 0.9411\n",
      "2025-11-13 10:52:24,349 - INFO - Training complete.\n",
      "2025-11-13 10:52:24,352 - INFO - {'loss': 0.24, 'accuracy': 0.913, 'f1': 0.782, 'roc_auc': 0.941, 'embedder.model_name': 'albert-base-v2', 'train_frac': 0.2, 'train_size': 29736, 'test_size': 33464, 'train_accounts': 196, 'test_accounts': 246}\n",
      "2025-11-13 10:52:24,362 - INFO - Yielding 30% split: 295 accounts, 42410 rows\n",
      "2025-11-13 10:52:24,365 - INFO - Embedding 42410 train texts...\n",
      "2025-11-13 10:52:25,202 - INFO - len(text_list)=42410 len(unique_texts)=26700 len(texts_to_embed)=0\n",
      "2025-11-13 10:52:26,057 - INFO - Embedding 33464 test texts...\n",
      "2025-11-13 10:52:26,341 - INFO - len(text_list)=33464 len(unique_texts)=20665 len(texts_to_embed)=0\n",
      "2025-11-13 10:52:26,993 - INFO - Fitting processor on 42410 rows...\n",
      "2025-11-13 10:52:26,994 - INFO - Fitting categorical amount features...\n",
      "2025-11-13 10:52:27,005 - INFO - Fit complete. Found 50 magic numbers.\n",
      "2025-11-13 10:52:27,006 - INFO - Created 20 fallback bins.\n",
      "2025-11-13 10:52:27,007 - INFO - Total Amount Vocabulary size: 72\n",
      "2025-11-13 10:52:27,007 - INFO - Fit complete. Found 50 magic numbers.\n",
      "2025-11-13 10:52:27,008 - INFO - Transforming 42410 rows...\n",
      "2025-11-13 10:52:27,168 - INFO - Transform complete.\n",
      "2025-11-13 10:52:27,169 - INFO - Transforming 33464 rows...\n",
      "2025-11-13 10:52:27,300 - INFO - Transform complete.\n",
      "Model Init: use_text=True, use_continuous=True, use_categorical=True\n",
      "Total input dim to MLP: 889\n",
      "2025-11-13 10:52:27,342 - INFO - Starting PyTorch training on cpu for 10 epochs...\n",
      "2025-11-13 10:52:29,662 - INFO - Epoch 1/10 [2.32s] | Train Loss: 0.4720 | Test Loss: 0.3122 | F1: 0.6624 | ROC-AUC: 0.8894\n",
      "2025-11-13 10:52:31,669 - INFO - Epoch 2/10 [2.01s] | Train Loss: 0.3024 | Test Loss: 0.2972 | F1: 0.5841 | ROC-AUC: 0.9255\n",
      "2025-11-13 10:52:33,741 - INFO - Epoch 3/10 [2.07s] | Train Loss: 0.2646 | Test Loss: 0.2650 | F1: 0.7323 | ROC-AUC: 0.9208\n",
      "2025-11-13 10:52:35,956 - INFO - Epoch 4/10 [2.21s] | Train Loss: 0.2468 | Test Loss: 0.2490 | F1: 0.7431 | ROC-AUC: 0.9309\n",
      "2025-11-13 10:52:38,171 - INFO - Epoch 5/10 [2.21s] | Train Loss: 0.2367 | Test Loss: 0.2311 | F1: 0.7509 | ROC-AUC: 0.9399\n",
      "2025-11-13 10:52:40,395 - INFO - Epoch 6/10 [2.22s] | Train Loss: 0.2276 | Test Loss: 0.2345 | F1: 0.7444 | ROC-AUC: 0.9395\n",
      "2025-11-13 10:52:42,431 - INFO - Epoch 7/10 [2.04s] | Train Loss: 0.2212 | Test Loss: 0.2272 | F1: 0.7805 | ROC-AUC: 0.9403\n",
      "2025-11-13 10:52:44,801 - INFO - Epoch 8/10 [2.37s] | Train Loss: 0.2164 | Test Loss: 0.2778 | F1: 0.6596 | ROC-AUC: 0.9353\n",
      "2025-11-13 10:52:47,041 - INFO - Epoch 9/10 [2.24s] | Train Loss: 0.2088 | Test Loss: 0.2218 | F1: 0.7627 | ROC-AUC: 0.9456\n",
      "2025-11-13 10:52:49,250 - INFO - Epoch 10/10 [2.21s] | Train Loss: 0.2072 | Test Loss: 0.2293 | F1: 0.7476 | ROC-AUC: 0.9413\n",
      "2025-11-13 10:52:49,250 - INFO - Training complete.\n",
      "2025-11-13 10:52:49,254 - INFO - {'loss': 0.227, 'accuracy': 0.917, 'f1': 0.781, 'roc_auc': 0.94, 'embedder.model_name': 'albert-base-v2', 'train_frac': 0.3, 'train_size': 42410, 'test_size': 33464, 'train_accounts': 295, 'test_accounts': 246}\n",
      "2025-11-13 10:52:49,269 - INFO - Yielding 40% split: 393 accounts, 59801 rows\n",
      "2025-11-13 10:52:49,271 - INFO - Embedding 59801 train texts...\n",
      "2025-11-13 10:52:51,821 - INFO - len(text_list)=59801 len(unique_texts)=37409 len(texts_to_embed)=0\n",
      "2025-11-13 10:52:53,743 - INFO - Embedding 33464 test texts...\n",
      "2025-11-13 10:52:54,078 - INFO - len(text_list)=33464 len(unique_texts)=20665 len(texts_to_embed)=0\n",
      "2025-11-13 10:52:54,981 - INFO - Fitting processor on 59801 rows...\n",
      "2025-11-13 10:52:54,982 - INFO - Fitting categorical amount features...\n",
      "2025-11-13 10:52:54,994 - INFO - Fit complete. Found 50 magic numbers.\n",
      "2025-11-13 10:52:54,995 - INFO - Created 20 fallback bins.\n",
      "2025-11-13 10:52:54,995 - INFO - Total Amount Vocabulary size: 72\n",
      "2025-11-13 10:52:54,996 - INFO - Fit complete. Found 50 magic numbers.\n",
      "2025-11-13 10:52:54,997 - INFO - Transforming 59801 rows...\n",
      "2025-11-13 10:52:55,373 - INFO - Transform complete.\n",
      "2025-11-13 10:52:55,375 - INFO - Transforming 33464 rows...\n",
      "2025-11-13 10:52:55,613 - INFO - Transform complete.\n",
      "Model Init: use_text=True, use_continuous=True, use_categorical=True\n",
      "Total input dim to MLP: 889\n",
      "2025-11-13 10:52:55,666 - INFO - Starting PyTorch training on cpu for 10 epochs...\n",
      "2025-11-13 10:52:59,819 - INFO - Epoch 1/10 [4.15s] | Train Loss: 0.4246 | Test Loss: 0.2757 | F1: 0.7018 | ROC-AUC: 0.9175\n",
      "2025-11-13 10:53:03,450 - INFO - Epoch 2/10 [3.63s] | Train Loss: 0.2832 | Test Loss: 0.2653 | F1: 0.7418 | ROC-AUC: 0.9265\n",
      "2025-11-13 10:53:07,990 - INFO - Epoch 3/10 [4.54s] | Train Loss: 0.2571 | Test Loss: 0.2579 | F1: 0.6874 | ROC-AUC: 0.9350\n",
      "2025-11-13 10:53:11,659 - INFO - Epoch 4/10 [3.67s] | Train Loss: 0.2450 | Test Loss: 0.2284 | F1: 0.7443 | ROC-AUC: 0.9431\n",
      "2025-11-13 10:53:15,276 - INFO - Epoch 5/10 [3.62s] | Train Loss: 0.2335 | Test Loss: 0.2724 | F1: 0.6751 | ROC-AUC: 0.9331\n",
      "2025-11-13 10:53:19,730 - INFO - Epoch 6/10 [4.45s] | Train Loss: 0.2254 | Test Loss: 0.2360 | F1: 0.7380 | ROC-AUC: 0.9412\n",
      "2025-11-13 10:53:24,214 - INFO - Epoch 7/10 [4.48s] | Train Loss: 0.2198 | Test Loss: 0.2212 | F1: 0.7729 | ROC-AUC: 0.9434\n",
      "2025-11-13 10:53:29,097 - INFO - Epoch 8/10 [4.88s] | Train Loss: 0.2162 | Test Loss: 0.2269 | F1: 0.7744 | ROC-AUC: 0.9400\n",
      "2025-11-13 10:53:34,272 - INFO - Epoch 9/10 [5.17s] | Train Loss: 0.2126 | Test Loss: 0.2560 | F1: 0.7197 | ROC-AUC: 0.9458\n",
      "2025-11-13 10:53:39,538 - INFO - Epoch 10/10 [5.26s] | Train Loss: 0.2121 | Test Loss: 0.2379 | F1: 0.7238 | ROC-AUC: 0.9403\n",
      "2025-11-13 10:53:39,539 - INFO - Training complete.\n",
      "2025-11-13 10:53:39,543 - INFO - {'loss': 0.227, 'accuracy': 0.917, 'f1': 0.774, 'roc_auc': 0.94, 'embedder.model_name': 'albert-base-v2', 'train_frac': 0.4, 'train_size': 59801, 'test_size': 33464, 'train_accounts': 393, 'test_accounts': 246}\n",
      "2025-11-13 10:53:39,558 - INFO - Yielding 50% split: 492 accounts, 75623 rows\n",
      "2025-11-13 10:53:39,561 - INFO - Embedding 75623 train texts...\n",
      "2025-11-13 10:53:41,564 - INFO - len(text_list)=75623 len(unique_texts)=46835 len(texts_to_embed)=0\n",
      "2025-11-13 10:53:43,052 - INFO - Embedding 33464 test texts...\n",
      "2025-11-13 10:53:43,356 - INFO - len(text_list)=33464 len(unique_texts)=20665 len(texts_to_embed)=0\n",
      "2025-11-13 10:53:44,114 - INFO - Fitting processor on 75623 rows...\n",
      "2025-11-13 10:53:44,115 - INFO - Fitting categorical amount features...\n",
      "2025-11-13 10:53:44,130 - INFO - Fit complete. Found 50 magic numbers.\n",
      "2025-11-13 10:53:44,131 - INFO - Created 20 fallback bins.\n",
      "2025-11-13 10:53:44,131 - INFO - Total Amount Vocabulary size: 72\n",
      "2025-11-13 10:53:44,132 - INFO - Fit complete. Found 50 magic numbers.\n",
      "2025-11-13 10:53:44,133 - INFO - Transforming 75623 rows...\n",
      "2025-11-13 10:53:44,385 - INFO - Transform complete.\n",
      "2025-11-13 10:53:44,385 - INFO - Transforming 33464 rows...\n",
      "2025-11-13 10:53:44,510 - INFO - Transform complete.\n",
      "Model Init: use_text=True, use_continuous=True, use_categorical=True\n",
      "Total input dim to MLP: 889\n",
      "2025-11-13 10:53:44,564 - INFO - Starting PyTorch training on cpu for 10 epochs...\n",
      "2025-11-13 10:53:48,935 - INFO - Epoch 1/10 [4.37s] | Train Loss: 0.4005 | Test Loss: 0.2887 | F1: 0.7135 | ROC-AUC: 0.9099\n",
      "2025-11-13 10:53:53,626 - INFO - Epoch 2/10 [4.69s] | Train Loss: 0.2692 | Test Loss: 0.2697 | F1: 0.7574 | ROC-AUC: 0.9242\n",
      "2025-11-13 10:53:59,037 - INFO - Epoch 3/10 [5.41s] | Train Loss: 0.2474 | Test Loss: 0.2426 | F1: 0.7265 | ROC-AUC: 0.9428\n",
      "2025-11-13 10:54:04,102 - INFO - Epoch 4/10 [5.06s] | Train Loss: 0.2339 | Test Loss: 0.2394 | F1: 0.7513 | ROC-AUC: 0.9337\n",
      "2025-11-13 10:54:09,242 - INFO - Epoch 5/10 [5.14s] | Train Loss: 0.2255 | Test Loss: 0.2340 | F1: 0.7716 | ROC-AUC: 0.9376\n",
      "2025-11-13 10:54:13,961 - INFO - Epoch 6/10 [4.72s] | Train Loss: 0.2186 | Test Loss: 0.2128 | F1: 0.7756 | ROC-AUC: 0.9499\n",
      "2025-11-13 10:54:19,061 - INFO - Epoch 7/10 [5.10s] | Train Loss: 0.2137 | Test Loss: 0.2097 | F1: 0.7949 | ROC-AUC: 0.9501\n",
      "2025-11-13 10:54:35,899 - INFO - Epoch 8/10 [16.84s] | Train Loss: 0.2105 | Test Loss: 0.2373 | F1: 0.7274 | ROC-AUC: 0.9486\n",
      "2025-11-13 10:54:47,133 - INFO - Epoch 9/10 [11.23s] | Train Loss: 0.2076 | Test Loss: 0.2052 | F1: 0.7887 | ROC-AUC: 0.9530\n",
      "2025-11-13 10:55:02,620 - INFO - Epoch 10/10 [15.48s] | Train Loss: 0.2054 | Test Loss: 0.2104 | F1: 0.7779 | ROC-AUC: 0.9513\n",
      "2025-11-13 10:55:02,622 - INFO - Training complete.\n",
      "2025-11-13 10:55:02,648 - INFO - {'loss': 0.21, 'accuracy': 0.923, 'f1': 0.795, 'roc_auc': 0.95, 'embedder.model_name': 'albert-base-v2', 'train_frac': 0.5, 'train_size': 75623, 'test_size': 33464, 'train_accounts': 492, 'test_accounts': 246}\n",
      "2025-11-13 10:55:02,697 - INFO - Yielding 60% split: 590 accounts, 92281 rows\n",
      "2025-11-13 10:55:02,716 - INFO - Embedding 92281 train texts...\n",
      "2025-11-13 10:55:08,733 - INFO - len(text_list)=92281 len(unique_texts)=56280 len(texts_to_embed)=0\n",
      "2025-11-13 10:55:10,704 - INFO - Embedding 33464 test texts...\n",
      "2025-11-13 10:55:11,002 - INFO - len(text_list)=33464 len(unique_texts)=20665 len(texts_to_embed)=0\n",
      "2025-11-13 10:55:11,674 - INFO - Fitting processor on 92281 rows...\n",
      "2025-11-13 10:55:11,675 - INFO - Fitting categorical amount features...\n",
      "2025-11-13 10:55:11,694 - INFO - Fit complete. Found 50 magic numbers.\n",
      "2025-11-13 10:55:11,695 - INFO - Created 20 fallback bins.\n",
      "2025-11-13 10:55:11,695 - INFO - Total Amount Vocabulary size: 72\n",
      "2025-11-13 10:55:11,696 - INFO - Fit complete. Found 50 magic numbers.\n",
      "2025-11-13 10:55:11,697 - INFO - Transforming 92281 rows...\n",
      "2025-11-13 10:55:12,091 - INFO - Transform complete.\n",
      "2025-11-13 10:55:12,092 - INFO - Transforming 33464 rows...\n",
      "2025-11-13 10:55:12,239 - INFO - Transform complete.\n",
      "Model Init: use_text=True, use_continuous=True, use_categorical=True\n",
      "Total input dim to MLP: 889\n",
      "2025-11-13 10:55:12,304 - INFO - Starting PyTorch training on cpu for 10 epochs...\n",
      "2025-11-13 10:55:20,325 - INFO - Epoch 1/10 [8.02s] | Train Loss: 0.3822 | Test Loss: 0.2588 | F1: 0.7008 | ROC-AUC: 0.9285\n",
      "2025-11-13 10:55:32,901 - INFO - Epoch 2/10 [12.57s] | Train Loss: 0.2648 | Test Loss: 0.2448 | F1: 0.7195 | ROC-AUC: 0.9416\n",
      "2025-11-13 10:55:48,781 - INFO - Epoch 3/10 [15.88s] | Train Loss: 0.2393 | Test Loss: 0.2260 | F1: 0.7693 | ROC-AUC: 0.9415\n",
      "2025-11-13 10:56:07,551 - INFO - Epoch 4/10 [18.77s] | Train Loss: 0.2310 | Test Loss: 0.2216 | F1: 0.7609 | ROC-AUC: 0.9473\n",
      "2025-11-13 10:56:18,351 - INFO - Epoch 5/10 [10.80s] | Train Loss: 0.2229 | Test Loss: 0.2822 | F1: 0.6314 | ROC-AUC: 0.9350\n",
      "2025-11-13 10:56:27,341 - INFO - Epoch 6/10 [8.99s] | Train Loss: 0.2195 | Test Loss: 0.2173 | F1: 0.7774 | ROC-AUC: 0.9495\n",
      "2025-11-13 10:56:36,475 - INFO - Epoch 7/10 [9.13s] | Train Loss: 0.2142 | Test Loss: 0.2157 | F1: 0.7682 | ROC-AUC: 0.9499\n",
      "2025-11-13 10:56:45,113 - INFO - Epoch 8/10 [8.64s] | Train Loss: 0.2090 | Test Loss: 0.1999 | F1: 0.8025 | ROC-AUC: 0.9559\n",
      "2025-11-13 10:56:54,059 - INFO - Epoch 9/10 [8.94s] | Train Loss: 0.2067 | Test Loss: 0.2086 | F1: 0.7814 | ROC-AUC: 0.9529\n",
      "2025-11-13 10:57:01,704 - INFO - Epoch 10/10 [7.64s] | Train Loss: 0.2036 | Test Loss: 0.2049 | F1: 0.7894 | ROC-AUC: 0.9528\n",
      "2025-11-13 10:57:01,705 - INFO - Training complete.\n",
      "2025-11-13 10:57:01,710 - INFO - {'loss': 0.2, 'accuracy': 0.926, 'f1': 0.803, 'roc_auc': 0.956, 'embedder.model_name': 'albert-base-v2', 'train_frac': 0.6, 'train_size': 92281, 'test_size': 33464, 'train_accounts': 590, 'test_accounts': 246}\n",
      "2025-11-13 10:57:01,725 - INFO - Yielding 70% split: 688 accounts, 108248 rows\n",
      "2025-11-13 10:57:01,729 - INFO - Embedding 108248 train texts...\n",
      "2025-11-13 10:57:04,083 - INFO - len(text_list)=108248 len(unique_texts)=65808 len(texts_to_embed)=0\n",
      "2025-11-13 10:57:06,911 - INFO - Embedding 33464 test texts...\n",
      "2025-11-13 10:57:07,214 - INFO - len(text_list)=33464 len(unique_texts)=20665 len(texts_to_embed)=0\n",
      "2025-11-13 10:57:08,074 - INFO - Fitting processor on 108248 rows...\n",
      "2025-11-13 10:57:08,075 - INFO - Fitting categorical amount features...\n",
      "2025-11-13 10:57:08,094 - INFO - Fit complete. Found 50 magic numbers.\n",
      "2025-11-13 10:57:08,095 - INFO - Created 20 fallback bins.\n",
      "2025-11-13 10:57:08,095 - INFO - Total Amount Vocabulary size: 72\n",
      "2025-11-13 10:57:08,096 - INFO - Fit complete. Found 50 magic numbers.\n",
      "2025-11-13 10:57:08,097 - INFO - Transforming 108248 rows...\n",
      "2025-11-13 10:57:08,556 - INFO - Transform complete.\n",
      "2025-11-13 10:57:08,556 - INFO - Transforming 33464 rows...\n",
      "2025-11-13 10:57:08,750 - INFO - Transform complete.\n",
      "Model Init: use_text=True, use_continuous=True, use_categorical=True\n",
      "Total input dim to MLP: 889\n",
      "2025-11-13 10:57:08,828 - INFO - Starting PyTorch training on cpu for 10 epochs...\n",
      "2025-11-13 10:57:16,001 - INFO - Epoch 1/10 [7.17s] | Train Loss: 0.3619 | Test Loss: 0.2553 | F1: 0.6938 | ROC-AUC: 0.9334\n",
      "2025-11-13 10:57:22,696 - INFO - Epoch 2/10 [6.69s] | Train Loss: 0.2565 | Test Loss: 0.2278 | F1: 0.7695 | ROC-AUC: 0.9431\n",
      "2025-11-13 10:57:29,625 - INFO - Epoch 3/10 [6.93s] | Train Loss: 0.2371 | Test Loss: 0.2279 | F1: 0.7791 | ROC-AUC: 0.9438\n",
      "2025-11-13 10:57:37,138 - INFO - Epoch 4/10 [7.51s] | Train Loss: 0.2251 | Test Loss: 0.2165 | F1: 0.7798 | ROC-AUC: 0.9483\n",
      "2025-11-13 10:57:44,798 - INFO - Epoch 5/10 [7.66s] | Train Loss: 0.2185 | Test Loss: 0.2384 | F1: 0.7201 | ROC-AUC: 0.9448\n",
      "2025-11-13 10:57:52,592 - INFO - Epoch 6/10 [7.79s] | Train Loss: 0.2141 | Test Loss: 0.2232 | F1: 0.7861 | ROC-AUC: 0.9487\n",
      "2025-11-13 10:57:58,988 - INFO - Epoch 7/10 [6.39s] | Train Loss: 0.2079 | Test Loss: 0.2029 | F1: 0.8033 | ROC-AUC: 0.9551\n",
      "2025-11-13 10:58:04,893 - INFO - Epoch 8/10 [5.90s] | Train Loss: 0.2057 | Test Loss: 0.2166 | F1: 0.7922 | ROC-AUC: 0.9485\n",
      "2025-11-13 10:58:11,903 - INFO - Epoch 9/10 [7.01s] | Train Loss: 0.2032 | Test Loss: 0.2064 | F1: 0.7955 | ROC-AUC: 0.9530\n",
      "2025-11-13 10:58:17,507 - INFO - Epoch 10/10 [5.60s] | Train Loss: 0.2013 | Test Loss: 0.2013 | F1: 0.7930 | ROC-AUC: 0.9553\n",
      "2025-11-13 10:58:17,508 - INFO - Training complete.\n",
      "2025-11-13 10:58:17,514 - INFO - {'loss': 0.203, 'accuracy': 0.923, 'f1': 0.803, 'roc_auc': 0.955, 'embedder.model_name': 'albert-base-v2', 'train_frac': 0.7, 'train_size': 108248, 'test_size': 33464, 'train_accounts': 688, 'test_accounts': 246}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T08:58:17.585780Z",
     "start_time": "2025-11-13T08:58:17.580274Z"
    }
   },
   "cell_type": "code",
   "source": "results",
   "id": "992cb940d94cdeb2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{16704: {'loss': 0.262,\n",
       "  'accuracy': 0.902,\n",
       "  'f1': 0.715,\n",
       "  'roc_auc': 0.926,\n",
       "  'embedder.model_name': 'albert-base-v2',\n",
       "  'train_frac': 0.1,\n",
       "  'train_size': 16704,\n",
       "  'test_size': 33464,\n",
       "  'train_accounts': 98,\n",
       "  'test_accounts': 246},\n",
       " 29736: {'loss': 0.24,\n",
       "  'accuracy': 0.913,\n",
       "  'f1': 0.782,\n",
       "  'roc_auc': 0.941,\n",
       "  'embedder.model_name': 'albert-base-v2',\n",
       "  'train_frac': 0.2,\n",
       "  'train_size': 29736,\n",
       "  'test_size': 33464,\n",
       "  'train_accounts': 196,\n",
       "  'test_accounts': 246},\n",
       " 42410: {'loss': 0.227,\n",
       "  'accuracy': 0.917,\n",
       "  'f1': 0.781,\n",
       "  'roc_auc': 0.94,\n",
       "  'embedder.model_name': 'albert-base-v2',\n",
       "  'train_frac': 0.3,\n",
       "  'train_size': 42410,\n",
       "  'test_size': 33464,\n",
       "  'train_accounts': 295,\n",
       "  'test_accounts': 246},\n",
       " 59801: {'loss': 0.227,\n",
       "  'accuracy': 0.917,\n",
       "  'f1': 0.774,\n",
       "  'roc_auc': 0.94,\n",
       "  'embedder.model_name': 'albert-base-v2',\n",
       "  'train_frac': 0.4,\n",
       "  'train_size': 59801,\n",
       "  'test_size': 33464,\n",
       "  'train_accounts': 393,\n",
       "  'test_accounts': 246},\n",
       " 75623: {'loss': 0.21,\n",
       "  'accuracy': 0.923,\n",
       "  'f1': 0.795,\n",
       "  'roc_auc': 0.95,\n",
       "  'embedder.model_name': 'albert-base-v2',\n",
       "  'train_frac': 0.5,\n",
       "  'train_size': 75623,\n",
       "  'test_size': 33464,\n",
       "  'train_accounts': 492,\n",
       "  'test_accounts': 246},\n",
       " 92281: {'loss': 0.2,\n",
       "  'accuracy': 0.926,\n",
       "  'f1': 0.803,\n",
       "  'roc_auc': 0.956,\n",
       "  'embedder.model_name': 'albert-base-v2',\n",
       "  'train_frac': 0.6,\n",
       "  'train_size': 92281,\n",
       "  'test_size': 33464,\n",
       "  'train_accounts': 590,\n",
       "  'test_accounts': 246},\n",
       " 108248: {'loss': 0.203,\n",
       "  'accuracy': 0.923,\n",
       "  'f1': 0.803,\n",
       "  'roc_auc': 0.955,\n",
       "  'embedder.model_name': 'albert-base-v2',\n",
       "  'train_frac': 0.7,\n",
       "  'train_size': 108248,\n",
       "  'test_size': 33464,\n",
       "  'train_accounts': 688,\n",
       "  'test_accounts': 246}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T09:02:38.406132Z",
     "start_time": "2025-11-13T08:58:17.591904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "runner2 = ExpRunner.copy(runner1)\n",
    "runner2.feat_proc_params = feat_params_off\n",
    "results2 = runner2.run_torch(fracs)\n"
   ],
   "id": "96f96304f4d9f7cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-13 10:58:17,599 - INFO - Splitting 189987 rows by group 'accountId'...\n",
      "2025-11-13 10:58:17,664 - INFO - Train accounts: 984, Test accounts: 246\n",
      "2025-11-13 10:58:17,665 - INFO - SUCCESS: No account overlap between train and test sets.\n",
      "2025-11-13 10:58:17,671 - INFO - Split complete. Train: len=156523 accounts=984, Test: len=33464 accounts=246.\n",
      "2025-11-13 10:58:17,674 - INFO - Preparing to create 7 training set fractions...\n",
      "2025-11-13 10:58:17,684 - INFO - Yielding 10% split: 98 accounts, 16704 rows\n",
      "2025-11-13 10:58:17,685 - INFO - Creating new EmbeddingService(model_name=albert-base-v2)\n",
      "2025-11-13 10:58:17,685 - INFO - Loading embedding model: albert-base-v2...\n",
      "2025-11-13 10:58:19,116 - INFO - Model albert-base-v2 loaded onto cpu. Cache at cache/albert-base-v2\n",
      "2025-11-13 10:58:19,117 - INFO - Embedding 16704 train texts...\n",
      "2025-11-13 10:58:19,231 - INFO - len(text_list)=16704 len(unique_texts)=10952 len(texts_to_embed)=0\n",
      "2025-11-13 10:58:19,464 - INFO - Embedding 33464 test texts...\n",
      "2025-11-13 10:58:19,711 - INFO - len(text_list)=33464 len(unique_texts)=20665 len(texts_to_embed)=0\n",
      "2025-11-13 10:58:20,265 - INFO - Fitting processor on 16704 rows...\n",
      "2025-11-13 10:58:20,266 - INFO - Transforming 16704 rows...\n",
      "2025-11-13 10:58:20,267 - INFO - Transform complete.\n",
      "2025-11-13 10:58:20,268 - INFO - Transforming 33464 rows...\n",
      "2025-11-13 10:58:20,270 - INFO - Transform complete.\n",
      "Model Init: use_text=True, use_continuous=False, use_categorical=False\n",
      "Total input dim to MLP: 768\n",
      "2025-11-13 10:58:20,289 - INFO - Starting PyTorch training on cpu for 10 epochs...\n",
      "2025-11-13 10:58:21,329 - INFO - Epoch 1/10 [1.04s] | Train Loss: 0.5519 | Test Loss: 0.7776 | F1: 0.4835 | ROC-AUC: 0.8445\n",
      "2025-11-13 10:58:22,333 - INFO - Epoch 2/10 [1.00s] | Train Loss: 0.3910 | Test Loss: 0.3685 | F1: 0.7084 | ROC-AUC: 0.8962\n",
      "2025-11-13 10:58:23,330 - INFO - Epoch 3/10 [1.00s] | Train Loss: 0.3041 | Test Loss: 0.4789 | F1: 0.6200 | ROC-AUC: 0.8811\n",
      "2025-11-13 10:58:24,299 - INFO - Epoch 4/10 [0.97s] | Train Loss: 0.2751 | Test Loss: 0.3085 | F1: 0.4591 | ROC-AUC: 0.9203\n",
      "2025-11-13 10:58:25,258 - INFO - Epoch 5/10 [0.96s] | Train Loss: 0.2601 | Test Loss: 0.2836 | F1: 0.7429 | ROC-AUC: 0.9081\n",
      "2025-11-13 10:58:26,296 - INFO - Epoch 6/10 [1.04s] | Train Loss: 0.2535 | Test Loss: 0.3462 | F1: 0.7172 | ROC-AUC: 0.9163\n",
      "2025-11-13 10:58:27,580 - INFO - Epoch 7/10 [1.28s] | Train Loss: 0.2381 | Test Loss: 0.3469 | F1: 0.6958 | ROC-AUC: 0.9082\n",
      "2025-11-13 10:58:28,752 - INFO - Epoch 8/10 [1.17s] | Train Loss: 0.2303 | Test Loss: 0.3447 | F1: 0.4125 | ROC-AUC: 0.9164\n",
      "2025-11-13 10:58:29,758 - INFO - Epoch 9/10 [1.01s] | Train Loss: 0.2273 | Test Loss: 0.2650 | F1: 0.7325 | ROC-AUC: 0.9246\n",
      "2025-11-13 10:58:30,771 - INFO - Epoch 10/10 [1.01s] | Train Loss: 0.2268 | Test Loss: 0.2573 | F1: 0.7564 | ROC-AUC: 0.9283\n",
      "2025-11-13 10:58:30,771 - INFO - Training complete.\n",
      "2025-11-13 10:58:30,777 - INFO - {'loss': 0.257, 'accuracy': 0.906, 'f1': 0.756, 'roc_auc': 0.928, 'embedder.model_name': 'albert-base-v2', 'train_frac': 0.1, 'train_size': 16704, 'test_size': 33464, 'train_accounts': 98, 'test_accounts': 246}\n",
      "2025-11-13 10:58:30,785 - INFO - Yielding 20% split: 196 accounts, 29736 rows\n",
      "2025-11-13 10:58:30,786 - INFO - Embedding 29736 train texts...\n",
      "2025-11-13 10:58:30,949 - INFO - len(text_list)=29736 len(unique_texts)=19347 len(texts_to_embed)=0\n",
      "2025-11-13 10:58:31,330 - INFO - Embedding 33464 test texts...\n",
      "2025-11-13 10:58:31,566 - INFO - len(text_list)=33464 len(unique_texts)=20665 len(texts_to_embed)=0\n",
      "2025-11-13 10:58:32,133 - INFO - Fitting processor on 29736 rows...\n",
      "2025-11-13 10:58:32,134 - INFO - Transforming 29736 rows...\n",
      "2025-11-13 10:58:32,135 - INFO - Transform complete.\n",
      "2025-11-13 10:58:32,136 - INFO - Transforming 33464 rows...\n",
      "2025-11-13 10:58:32,136 - INFO - Transform complete.\n",
      "Model Init: use_text=True, use_continuous=False, use_categorical=False\n",
      "Total input dim to MLP: 768\n",
      "2025-11-13 10:58:32,160 - INFO - Starting PyTorch training on cpu for 10 epochs...\n",
      "2025-11-13 10:58:33,713 - INFO - Epoch 1/10 [1.55s] | Train Loss: 0.4994 | Test Loss: 0.4231 | F1: 0.6875 | ROC-AUC: 0.8898\n",
      "2025-11-13 10:58:35,197 - INFO - Epoch 2/10 [1.48s] | Train Loss: 0.3209 | Test Loss: 0.3152 | F1: 0.6954 | ROC-AUC: 0.8854\n",
      "2025-11-13 10:58:36,882 - INFO - Epoch 3/10 [1.68s] | Train Loss: 0.2751 | Test Loss: 0.2986 | F1: 0.5519 | ROC-AUC: 0.9150\n",
      "2025-11-13 10:58:38,399 - INFO - Epoch 4/10 [1.52s] | Train Loss: 0.2553 | Test Loss: 0.2661 | F1: 0.7161 | ROC-AUC: 0.9180\n",
      "2025-11-13 10:58:39,881 - INFO - Epoch 5/10 [1.48s] | Train Loss: 0.2420 | Test Loss: 0.3732 | F1: 0.4033 | ROC-AUC: 0.9143\n",
      "2025-11-13 10:58:41,366 - INFO - Epoch 6/10 [1.48s] | Train Loss: 0.2310 | Test Loss: 0.2657 | F1: 0.6913 | ROC-AUC: 0.9176\n",
      "2025-11-13 10:58:42,913 - INFO - Epoch 7/10 [1.55s] | Train Loss: 0.2249 | Test Loss: 0.2583 | F1: 0.7319 | ROC-AUC: 0.9331\n",
      "2025-11-13 10:58:44,574 - INFO - Epoch 8/10 [1.66s] | Train Loss: 0.2238 | Test Loss: 0.4175 | F1: 0.4920 | ROC-AUC: 0.8932\n",
      "2025-11-13 10:58:46,162 - INFO - Epoch 9/10 [1.59s] | Train Loss: 0.2206 | Test Loss: 0.2711 | F1: 0.6887 | ROC-AUC: 0.9176\n",
      "2025-11-13 10:58:47,817 - INFO - Epoch 10/10 [1.65s] | Train Loss: 0.2074 | Test Loss: 0.2422 | F1: 0.7592 | ROC-AUC: 0.9336\n",
      "2025-11-13 10:58:47,817 - INFO - Training complete.\n",
      "2025-11-13 10:58:47,820 - INFO - {'loss': 0.242, 'accuracy': 0.909, 'f1': 0.759, 'roc_auc': 0.934, 'embedder.model_name': 'albert-base-v2', 'train_frac': 0.2, 'train_size': 29736, 'test_size': 33464, 'train_accounts': 196, 'test_accounts': 246}\n",
      "2025-11-13 10:58:47,828 - INFO - Yielding 30% split: 295 accounts, 42410 rows\n",
      "2025-11-13 10:58:47,829 - INFO - Embedding 42410 train texts...\n",
      "2025-11-13 10:58:48,066 - INFO - len(text_list)=42410 len(unique_texts)=26700 len(texts_to_embed)=0\n",
      "2025-11-13 10:58:48,783 - INFO - Embedding 33464 test texts...\n",
      "2025-11-13 10:58:49,032 - INFO - len(text_list)=33464 len(unique_texts)=20665 len(texts_to_embed)=0\n",
      "2025-11-13 10:58:49,617 - INFO - Fitting processor on 42410 rows...\n",
      "2025-11-13 10:58:49,618 - INFO - Transforming 42410 rows...\n",
      "2025-11-13 10:58:49,619 - INFO - Transform complete.\n",
      "2025-11-13 10:58:49,620 - INFO - Transforming 33464 rows...\n",
      "2025-11-13 10:58:49,621 - INFO - Transform complete.\n",
      "Model Init: use_text=True, use_continuous=False, use_categorical=False\n",
      "Total input dim to MLP: 768\n",
      "2025-11-13 10:58:49,657 - INFO - Starting PyTorch training on cpu for 10 epochs...\n",
      "2025-11-13 10:58:51,726 - INFO - Epoch 1/10 [2.07s] | Train Loss: 0.4718 | Test Loss: 0.3596 | F1: 0.6551 | ROC-AUC: 0.8748\n",
      "2025-11-13 10:58:53,660 - INFO - Epoch 2/10 [1.93s] | Train Loss: 0.3049 | Test Loss: 0.3403 | F1: 0.7034 | ROC-AUC: 0.8995\n",
      "2025-11-13 10:58:55,473 - INFO - Epoch 3/10 [1.81s] | Train Loss: 0.2757 | Test Loss: 0.2483 | F1: 0.7505 | ROC-AUC: 0.9281\n",
      "2025-11-13 10:58:57,277 - INFO - Epoch 4/10 [1.80s] | Train Loss: 0.2567 | Test Loss: 0.2492 | F1: 0.7466 | ROC-AUC: 0.9265\n",
      "2025-11-13 10:58:59,688 - INFO - Epoch 5/10 [2.41s] | Train Loss: 0.2455 | Test Loss: 0.2340 | F1: 0.7635 | ROC-AUC: 0.9359\n",
      "2025-11-13 10:59:02,026 - INFO - Epoch 6/10 [2.34s] | Train Loss: 0.2376 | Test Loss: 0.2447 | F1: 0.7266 | ROC-AUC: 0.9357\n",
      "2025-11-13 10:59:04,117 - INFO - Epoch 7/10 [2.09s] | Train Loss: 0.2322 | Test Loss: 0.2953 | F1: 0.7274 | ROC-AUC: 0.8989\n",
      "2025-11-13 10:59:06,510 - INFO - Epoch 8/10 [2.39s] | Train Loss: 0.2243 | Test Loss: 0.3228 | F1: 0.5202 | ROC-AUC: 0.9249\n",
      "2025-11-13 10:59:08,543 - INFO - Epoch 9/10 [2.03s] | Train Loss: 0.2243 | Test Loss: 0.2387 | F1: 0.7597 | ROC-AUC: 0.9323\n",
      "2025-11-13 10:59:10,789 - INFO - Epoch 10/10 [2.25s] | Train Loss: 0.2187 | Test Loss: 0.2396 | F1: 0.7624 | ROC-AUC: 0.9365\n",
      "2025-11-13 10:59:10,790 - INFO - Training complete.\n",
      "2025-11-13 10:59:10,793 - INFO - {'loss': 0.234, 'accuracy': 0.914, 'f1': 0.764, 'roc_auc': 0.936, 'embedder.model_name': 'albert-base-v2', 'train_frac': 0.3, 'train_size': 42410, 'test_size': 33464, 'train_accounts': 295, 'test_accounts': 246}\n",
      "2025-11-13 10:59:10,804 - INFO - Yielding 40% split: 393 accounts, 59801 rows\n",
      "2025-11-13 10:59:10,805 - INFO - Embedding 59801 train texts...\n",
      "2025-11-13 10:59:11,198 - INFO - len(text_list)=59801 len(unique_texts)=37409 len(texts_to_embed)=0\n",
      "2025-11-13 10:59:12,188 - INFO - Embedding 33464 test texts...\n",
      "2025-11-13 10:59:12,434 - INFO - len(text_list)=33464 len(unique_texts)=20665 len(texts_to_embed)=0\n",
      "2025-11-13 10:59:13,099 - INFO - Fitting processor on 59801 rows...\n",
      "2025-11-13 10:59:13,100 - INFO - Transforming 59801 rows...\n",
      "2025-11-13 10:59:13,101 - INFO - Transform complete.\n",
      "2025-11-13 10:59:13,101 - INFO - Transforming 33464 rows...\n",
      "2025-11-13 10:59:13,102 - INFO - Transform complete.\n",
      "Model Init: use_text=True, use_continuous=False, use_categorical=False\n",
      "Total input dim to MLP: 768\n",
      "2025-11-13 10:59:13,136 - INFO - Starting PyTorch training on cpu for 10 epochs...\n",
      "2025-11-13 10:59:15,508 - INFO - Epoch 1/10 [2.37s] | Train Loss: 0.4281 | Test Loss: 0.2996 | F1: 0.5646 | ROC-AUC: 0.9043\n",
      "2025-11-13 10:59:17,930 - INFO - Epoch 2/10 [2.42s] | Train Loss: 0.2929 | Test Loss: 0.3358 | F1: 0.5530 | ROC-AUC: 0.9075\n",
      "2025-11-13 10:59:20,321 - INFO - Epoch 3/10 [2.39s] | Train Loss: 0.2660 | Test Loss: 0.2701 | F1: 0.6958 | ROC-AUC: 0.9238\n",
      "2025-11-13 10:59:23,136 - INFO - Epoch 4/10 [2.81s] | Train Loss: 0.2537 | Test Loss: 0.2823 | F1: 0.7408 | ROC-AUC: 0.9200\n",
      "2025-11-13 10:59:25,923 - INFO - Epoch 5/10 [2.79s] | Train Loss: 0.2446 | Test Loss: 0.2437 | F1: 0.7255 | ROC-AUC: 0.9357\n",
      "2025-11-13 10:59:29,316 - INFO - Epoch 6/10 [3.39s] | Train Loss: 0.2355 | Test Loss: 0.2316 | F1: 0.7697 | ROC-AUC: 0.9387\n",
      "2025-11-13 10:59:33,570 - INFO - Epoch 7/10 [4.25s] | Train Loss: 0.2284 | Test Loss: 0.2400 | F1: 0.7272 | ROC-AUC: 0.9399\n",
      "2025-11-13 10:59:36,547 - INFO - Epoch 8/10 [2.98s] | Train Loss: 0.2241 | Test Loss: 0.2481 | F1: 0.6922 | ROC-AUC: 0.9401\n",
      "2025-11-13 10:59:39,521 - INFO - Epoch 9/10 [2.97s] | Train Loss: 0.2216 | Test Loss: 0.2336 | F1: 0.7724 | ROC-AUC: 0.9400\n",
      "2025-11-13 10:59:42,507 - INFO - Epoch 10/10 [2.99s] | Train Loss: 0.2167 | Test Loss: 0.2221 | F1: 0.7853 | ROC-AUC: 0.9456\n",
      "2025-11-13 10:59:42,508 - INFO - Training complete.\n",
      "2025-11-13 10:59:42,512 - INFO - {'loss': 0.222, 'accuracy': 0.919, 'f1': 0.785, 'roc_auc': 0.946, 'embedder.model_name': 'albert-base-v2', 'train_frac': 0.4, 'train_size': 59801, 'test_size': 33464, 'train_accounts': 393, 'test_accounts': 246}\n",
      "2025-11-13 10:59:42,522 - INFO - Yielding 50% split: 492 accounts, 75623 rows\n",
      "2025-11-13 10:59:42,524 - INFO - Embedding 75623 train texts...\n",
      "2025-11-13 10:59:43,007 - INFO - len(text_list)=75623 len(unique_texts)=46835 len(texts_to_embed)=0\n",
      "2025-11-13 10:59:44,297 - INFO - Embedding 33464 test texts...\n",
      "2025-11-13 10:59:44,553 - INFO - len(text_list)=33464 len(unique_texts)=20665 len(texts_to_embed)=0\n",
      "2025-11-13 10:59:45,124 - INFO - Fitting processor on 75623 rows...\n",
      "2025-11-13 10:59:45,125 - INFO - Transforming 75623 rows...\n",
      "2025-11-13 10:59:45,126 - INFO - Transform complete.\n",
      "2025-11-13 10:59:45,127 - INFO - Transforming 33464 rows...\n",
      "2025-11-13 10:59:45,129 - INFO - Transform complete.\n",
      "Model Init: use_text=True, use_continuous=False, use_categorical=False\n",
      "Total input dim to MLP: 768\n",
      "2025-11-13 10:59:45,173 - INFO - Starting PyTorch training on cpu for 10 epochs...\n",
      "2025-11-13 10:59:48,310 - INFO - Epoch 1/10 [3.14s] | Train Loss: 0.4044 | Test Loss: 0.3549 | F1: 0.5354 | ROC-AUC: 0.8700\n",
      "2025-11-13 10:59:51,506 - INFO - Epoch 2/10 [3.20s] | Train Loss: 0.2764 | Test Loss: 0.2933 | F1: 0.7370 | ROC-AUC: 0.9212\n",
      "2025-11-13 10:59:54,708 - INFO - Epoch 3/10 [3.20s] | Train Loss: 0.2516 | Test Loss: 0.2418 | F1: 0.7317 | ROC-AUC: 0.9347\n",
      "2025-11-13 10:59:58,422 - INFO - Epoch 4/10 [3.71s] | Train Loss: 0.2408 | Test Loss: 0.2620 | F1: 0.6396 | ROC-AUC: 0.9376\n",
      "2025-11-13 11:00:02,429 - INFO - Epoch 5/10 [4.01s] | Train Loss: 0.2339 | Test Loss: 0.2778 | F1: 0.6590 | ROC-AUC: 0.9332\n",
      "2025-11-13 11:00:07,464 - INFO - Epoch 6/10 [5.03s] | Train Loss: 0.2286 | Test Loss: 0.2470 | F1: 0.7216 | ROC-AUC: 0.9401\n",
      "2025-11-13 11:00:14,160 - INFO - Epoch 7/10 [6.69s] | Train Loss: 0.2232 | Test Loss: 0.2936 | F1: 0.7363 | ROC-AUC: 0.9161\n",
      "2025-11-13 11:00:21,012 - INFO - Epoch 8/10 [6.85s] | Train Loss: 0.2190 | Test Loss: 0.2213 | F1: 0.7815 | ROC-AUC: 0.9458\n",
      "2025-11-13 11:00:27,910 - INFO - Epoch 9/10 [6.90s] | Train Loss: 0.2158 | Test Loss: 0.2235 | F1: 0.7849 | ROC-AUC: 0.9462\n",
      "2025-11-13 11:00:33,126 - INFO - Epoch 10/10 [5.22s] | Train Loss: 0.2125 | Test Loss: 0.2303 | F1: 0.7525 | ROC-AUC: 0.9448\n",
      "2025-11-13 11:00:33,127 - INFO - Training complete.\n",
      "2025-11-13 11:00:33,132 - INFO - {'loss': 0.224, 'accuracy': 0.917, 'f1': 0.785, 'roc_auc': 0.946, 'embedder.model_name': 'albert-base-v2', 'train_frac': 0.5, 'train_size': 75623, 'test_size': 33464, 'train_accounts': 492, 'test_accounts': 246}\n",
      "2025-11-13 11:00:33,144 - INFO - Yielding 60% split: 590 accounts, 92281 rows\n",
      "2025-11-13 11:00:33,146 - INFO - Embedding 92281 train texts...\n",
      "2025-11-13 11:00:33,921 - INFO - len(text_list)=92281 len(unique_texts)=56280 len(texts_to_embed)=0\n",
      "2025-11-13 11:00:36,343 - INFO - Embedding 33464 test texts...\n",
      "2025-11-13 11:00:36,968 - INFO - len(text_list)=33464 len(unique_texts)=20665 len(texts_to_embed)=0\n",
      "2025-11-13 11:00:37,568 - INFO - Fitting processor on 92281 rows...\n",
      "2025-11-13 11:00:37,569 - INFO - Transforming 92281 rows...\n",
      "2025-11-13 11:00:37,570 - INFO - Transform complete.\n",
      "2025-11-13 11:00:37,571 - INFO - Transforming 33464 rows...\n",
      "2025-11-13 11:00:37,572 - INFO - Transform complete.\n",
      "Model Init: use_text=True, use_continuous=False, use_categorical=False\n",
      "Total input dim to MLP: 768\n",
      "2025-11-13 11:00:37,623 - INFO - Starting PyTorch training on cpu for 10 epochs...\n",
      "2025-11-13 11:00:44,295 - INFO - Epoch 1/10 [6.67s] | Train Loss: 0.3847 | Test Loss: 0.2477 | F1: 0.7456 | ROC-AUC: 0.9296\n",
      "2025-11-13 11:00:49,927 - INFO - Epoch 2/10 [5.63s] | Train Loss: 0.2721 | Test Loss: 0.2618 | F1: 0.6703 | ROC-AUC: 0.9237\n",
      "2025-11-13 11:00:55,697 - INFO - Epoch 3/10 [5.77s] | Train Loss: 0.2495 | Test Loss: 0.2544 | F1: 0.7756 | ROC-AUC: 0.9205\n",
      "2025-11-13 11:01:01,332 - INFO - Epoch 4/10 [5.63s] | Train Loss: 0.2394 | Test Loss: 0.2620 | F1: 0.6628 | ROC-AUC: 0.9362\n",
      "2025-11-13 11:01:07,512 - INFO - Epoch 5/10 [6.18s] | Train Loss: 0.2313 | Test Loss: 0.2257 | F1: 0.7882 | ROC-AUC: 0.9429\n",
      "2025-11-13 11:01:13,774 - INFO - Epoch 6/10 [6.26s] | Train Loss: 0.2268 | Test Loss: 0.2155 | F1: 0.7884 | ROC-AUC: 0.9465\n",
      "2025-11-13 11:01:19,062 - INFO - Epoch 7/10 [5.29s] | Train Loss: 0.2239 | Test Loss: 0.2299 | F1: 0.7604 | ROC-AUC: 0.9434\n",
      "2025-11-13 11:01:24,299 - INFO - Epoch 8/10 [5.24s] | Train Loss: 0.2194 | Test Loss: 0.2408 | F1: 0.7214 | ROC-AUC: 0.9367\n",
      "2025-11-13 11:01:29,505 - INFO - Epoch 9/10 [5.21s] | Train Loss: 0.2178 | Test Loss: 0.2151 | F1: 0.7951 | ROC-AUC: 0.9464\n",
      "2025-11-13 11:01:34,945 - INFO - Epoch 10/10 [5.44s] | Train Loss: 0.2150 | Test Loss: 0.4414 | F1: 0.6477 | ROC-AUC: 0.9197\n",
      "2025-11-13 11:01:34,946 - INFO - Training complete.\n",
      "2025-11-13 11:01:34,952 - INFO - {'loss': 0.215, 'accuracy': 0.924, 'f1': 0.795, 'roc_auc': 0.946, 'embedder.model_name': 'albert-base-v2', 'train_frac': 0.6, 'train_size': 92281, 'test_size': 33464, 'train_accounts': 590, 'test_accounts': 246}\n",
      "2025-11-13 11:01:34,966 - INFO - Yielding 70% split: 688 accounts, 108248 rows\n",
      "2025-11-13 11:01:34,968 - INFO - Embedding 108248 train texts...\n",
      "2025-11-13 11:01:35,863 - INFO - len(text_list)=108248 len(unique_texts)=65808 len(texts_to_embed)=0\n",
      "2025-11-13 11:01:38,133 - INFO - Embedding 33464 test texts...\n",
      "2025-11-13 11:01:38,363 - INFO - len(text_list)=33464 len(unique_texts)=20665 len(texts_to_embed)=0\n",
      "2025-11-13 11:01:38,986 - INFO - Fitting processor on 108248 rows...\n",
      "2025-11-13 11:01:38,987 - INFO - Transforming 108248 rows...\n",
      "2025-11-13 11:01:38,988 - INFO - Transform complete.\n",
      "2025-11-13 11:01:38,989 - INFO - Transforming 33464 rows...\n",
      "2025-11-13 11:01:38,990 - INFO - Transform complete.\n",
      "Model Init: use_text=True, use_continuous=False, use_categorical=False\n",
      "Total input dim to MLP: 768\n",
      "2025-11-13 11:01:39,040 - INFO - Starting PyTorch training on cpu for 10 epochs...\n",
      "2025-11-13 11:01:44,480 - INFO - Epoch 1/10 [5.44s] | Train Loss: 0.3689 | Test Loss: 0.2704 | F1: 0.7505 | ROC-AUC: 0.9055\n",
      "2025-11-13 11:01:49,833 - INFO - Epoch 2/10 [5.35s] | Train Loss: 0.2659 | Test Loss: 0.2843 | F1: 0.7481 | ROC-AUC: 0.9157\n",
      "2025-11-13 11:01:55,718 - INFO - Epoch 3/10 [5.88s] | Train Loss: 0.2449 | Test Loss: 0.2479 | F1: 0.7728 | ROC-AUC: 0.9368\n",
      "2025-11-13 11:02:01,673 - INFO - Epoch 4/10 [5.95s] | Train Loss: 0.2353 | Test Loss: 0.6923 | F1: 0.5421 | ROC-AUC: 0.8731\n",
      "2025-11-13 11:02:08,115 - INFO - Epoch 5/10 [6.44s] | Train Loss: 0.2268 | Test Loss: 0.2249 | F1: 0.7888 | ROC-AUC: 0.9426\n",
      "2025-11-13 11:02:14,202 - INFO - Epoch 6/10 [6.09s] | Train Loss: 0.2224 | Test Loss: 0.2778 | F1: 0.7422 | ROC-AUC: 0.9232\n",
      "2025-11-13 11:02:20,159 - INFO - Epoch 7/10 [5.96s] | Train Loss: 0.2198 | Test Loss: 0.2164 | F1: 0.7876 | ROC-AUC: 0.9452\n",
      "2025-11-13 11:02:26,110 - INFO - Epoch 8/10 [5.95s] | Train Loss: 0.2159 | Test Loss: 0.2119 | F1: 0.7822 | ROC-AUC: 0.9496\n",
      "2025-11-13 11:02:31,979 - INFO - Epoch 9/10 [5.87s] | Train Loss: 0.2117 | Test Loss: 0.2202 | F1: 0.7880 | ROC-AUC: 0.9477\n",
      "2025-11-13 11:02:38,372 - INFO - Epoch 10/10 [6.39s] | Train Loss: 0.2123 | Test Loss: 0.2286 | F1: 0.7836 | ROC-AUC: 0.9402\n",
      "2025-11-13 11:02:38,373 - INFO - Training complete.\n",
      "2025-11-13 11:02:38,379 - INFO - {'loss': 0.225, 'accuracy': 0.922, 'f1': 0.789, 'roc_auc': 0.943, 'embedder.model_name': 'albert-base-v2', 'train_frac': 0.7, 'train_size': 108248, 'test_size': 33464, 'train_accounts': 688, 'test_accounts': 246}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T09:02:38.463755Z",
     "start_time": "2025-11-13T09:02:38.460750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# runner3 = ExpRunner.copy(runner1)\n",
    "# runner3.feat_proc_params = FeatProcParams(n_bins=20, k_top=50)\n",
    "# runner3.run_torch([0.1])\n"
   ],
   "id": "a26f355bbf7e1888",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T09:07:11.193356Z",
     "start_time": "2025-11-13T09:02:38.472669Z"
    }
   },
   "cell_type": "code",
   "source": "results2 = runner2.run_torch(fracs)\n",
   "id": "5b1cc1626d140f29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-13 11:02:38,482 - INFO - Splitting 189987 rows by group 'accountId'...\n",
      "2025-11-13 11:02:38,590 - INFO - Train accounts: 984, Test accounts: 246\n",
      "2025-11-13 11:02:38,591 - INFO - SUCCESS: No account overlap between train and test sets.\n",
      "2025-11-13 11:02:38,600 - INFO - Split complete. Train: len=156523 accounts=984, Test: len=33464 accounts=246.\n",
      "2025-11-13 11:02:38,604 - INFO - Preparing to create 7 training set fractions...\n",
      "2025-11-13 11:02:38,623 - INFO - Yielding 10% split: 98 accounts, 16704 rows\n",
      "2025-11-13 11:02:38,625 - INFO - Embedding 16704 train texts...\n",
      "2025-11-13 11:02:38,733 - INFO - len(text_list)=16704 len(unique_texts)=10952 len(texts_to_embed)=0\n",
      "2025-11-13 11:02:38,993 - INFO - Embedding 33464 test texts...\n",
      "2025-11-13 11:02:39,312 - INFO - len(text_list)=33464 len(unique_texts)=20665 len(texts_to_embed)=0\n",
      "2025-11-13 11:02:39,959 - INFO - Fitting processor on 16704 rows...\n",
      "2025-11-13 11:02:39,959 - INFO - Transforming 16704 rows...\n",
      "2025-11-13 11:02:39,961 - INFO - Transform complete.\n",
      "2025-11-13 11:02:39,962 - INFO - Transforming 33464 rows...\n",
      "2025-11-13 11:02:39,962 - INFO - Transform complete.\n",
      "Model Init: use_text=True, use_continuous=False, use_categorical=False\n",
      "Total input dim to MLP: 768\n",
      "2025-11-13 11:02:39,978 - INFO - Starting PyTorch training on cpu for 10 epochs...\n",
      "2025-11-13 11:02:41,439 - INFO - Epoch 1/10 [1.46s] | Train Loss: 0.5708 | Test Loss: 0.3556 | F1: 0.5547 | ROC-AUC: 0.8603\n",
      "2025-11-13 11:02:42,786 - INFO - Epoch 2/10 [1.35s] | Train Loss: 0.4010 | Test Loss: 0.3121 | F1: 0.5623 | ROC-AUC: 0.9067\n",
      "2025-11-13 11:02:44,163 - INFO - Epoch 3/10 [1.38s] | Train Loss: 0.3129 | Test Loss: 0.3160 | F1: 0.6104 | ROC-AUC: 0.9060\n",
      "2025-11-13 11:02:46,242 - INFO - Epoch 4/10 [2.08s] | Train Loss: 0.2808 | Test Loss: 0.3521 | F1: 0.5347 | ROC-AUC: 0.8816\n",
      "2025-11-13 11:02:47,901 - INFO - Epoch 5/10 [1.66s] | Train Loss: 0.2688 | Test Loss: 0.4034 | F1: 0.6166 | ROC-AUC: 0.8600\n",
      "2025-11-13 11:02:49,722 - INFO - Epoch 6/10 [1.82s] | Train Loss: 0.2533 | Test Loss: 0.3691 | F1: 0.4167 | ROC-AUC: 0.9130\n",
      "2025-11-13 11:02:51,125 - INFO - Epoch 7/10 [1.40s] | Train Loss: 0.2423 | Test Loss: 0.3550 | F1: 0.5196 | ROC-AUC: 0.9240\n",
      "2025-11-13 11:02:52,691 - INFO - Epoch 8/10 [1.57s] | Train Loss: 0.2369 | Test Loss: 0.3674 | F1: 0.4905 | ROC-AUC: 0.9060\n",
      "2025-11-13 11:02:54,287 - INFO - Epoch 9/10 [1.59s] | Train Loss: 0.2284 | Test Loss: 0.2967 | F1: 0.5940 | ROC-AUC: 0.9211\n",
      "2025-11-13 11:02:55,629 - INFO - Epoch 10/10 [1.34s] | Train Loss: 0.2293 | Test Loss: 0.3218 | F1: 0.5582 | ROC-AUC: 0.9223\n",
      "2025-11-13 11:02:55,630 - INFO - Training complete.\n",
      "2025-11-13 11:02:55,653 - INFO - {'loss': 0.403, 'accuracy': 0.837, 'f1': 0.617, 'roc_auc': 0.86, 'embedder.model_name': 'albert-base-v2', 'train_frac': 0.1, 'train_size': 16704, 'test_size': 33464, 'train_accounts': 98, 'test_accounts': 246}\n",
      "2025-11-13 11:02:55,666 - INFO - Yielding 20% split: 196 accounts, 29736 rows\n",
      "2025-11-13 11:02:55,667 - INFO - Embedding 29736 train texts...\n",
      "2025-11-13 11:02:55,815 - INFO - len(text_list)=29736 len(unique_texts)=19347 len(texts_to_embed)=0\n",
      "2025-11-13 11:02:56,229 - INFO - Embedding 33464 test texts...\n",
      "2025-11-13 11:02:56,465 - INFO - len(text_list)=33464 len(unique_texts)=20665 len(texts_to_embed)=0\n",
      "2025-11-13 11:02:57,067 - INFO - Fitting processor on 29736 rows...\n",
      "2025-11-13 11:02:57,068 - INFO - Transforming 29736 rows...\n",
      "2025-11-13 11:02:57,069 - INFO - Transform complete.\n",
      "2025-11-13 11:02:57,070 - INFO - Transforming 33464 rows...\n",
      "2025-11-13 11:02:57,071 - INFO - Transform complete.\n",
      "Model Init: use_text=True, use_continuous=False, use_categorical=False\n",
      "Total input dim to MLP: 768\n",
      "2025-11-13 11:02:57,095 - INFO - Starting PyTorch training on cpu for 10 epochs...\n",
      "2025-11-13 11:02:59,067 - INFO - Epoch 1/10 [1.97s] | Train Loss: 0.5145 | Test Loss: 0.3729 | F1: 0.7036 | ROC-AUC: 0.8844\n",
      "2025-11-13 11:03:01,018 - INFO - Epoch 2/10 [1.95s] | Train Loss: 0.3266 | Test Loss: 0.3683 | F1: 0.3295 | ROC-AUC: 0.9103\n",
      "2025-11-13 11:03:02,971 - INFO - Epoch 3/10 [1.95s] | Train Loss: 0.2775 | Test Loss: 0.3826 | F1: 0.6853 | ROC-AUC: 0.8933\n",
      "2025-11-13 11:03:04,907 - INFO - Epoch 4/10 [1.94s] | Train Loss: 0.2604 | Test Loss: 0.2470 | F1: 0.7298 | ROC-AUC: 0.9306\n",
      "2025-11-13 11:03:06,992 - INFO - Epoch 5/10 [2.08s] | Train Loss: 0.2469 | Test Loss: 0.2616 | F1: 0.6976 | ROC-AUC: 0.9200\n",
      "2025-11-13 11:03:08,889 - INFO - Epoch 6/10 [1.90s] | Train Loss: 0.2412 | Test Loss: 0.2707 | F1: 0.7441 | ROC-AUC: 0.9115\n",
      "2025-11-13 11:03:10,896 - INFO - Epoch 7/10 [2.01s] | Train Loss: 0.2282 | Test Loss: 0.2649 | F1: 0.6617 | ROC-AUC: 0.9356\n",
      "2025-11-13 11:03:13,016 - INFO - Epoch 8/10 [2.12s] | Train Loss: 0.2252 | Test Loss: 0.2498 | F1: 0.7680 | ROC-AUC: 0.9224\n",
      "2025-11-13 11:03:15,112 - INFO - Epoch 9/10 [2.10s] | Train Loss: 0.2225 | Test Loss: 0.2351 | F1: 0.7680 | ROC-AUC: 0.9385\n",
      "2025-11-13 11:03:17,182 - INFO - Epoch 10/10 [2.07s] | Train Loss: 0.2151 | Test Loss: 0.2338 | F1: 0.7630 | ROC-AUC: 0.9367\n",
      "2025-11-13 11:03:17,183 - INFO - Training complete.\n",
      "2025-11-13 11:03:17,186 - INFO - {'loss': 0.235, 'accuracy': 0.912, 'f1': 0.768, 'roc_auc': 0.938, 'embedder.model_name': 'albert-base-v2', 'train_frac': 0.2, 'train_size': 29736, 'test_size': 33464, 'train_accounts': 196, 'test_accounts': 246}\n",
      "2025-11-13 11:03:17,193 - INFO - Yielding 30% split: 295 accounts, 42410 rows\n",
      "2025-11-13 11:03:17,194 - INFO - Embedding 42410 train texts...\n",
      "2025-11-13 11:03:17,470 - INFO - len(text_list)=42410 len(unique_texts)=26700 len(texts_to_embed)=0\n",
      "2025-11-13 11:03:18,170 - INFO - Embedding 33464 test texts...\n",
      "2025-11-13 11:03:18,399 - INFO - len(text_list)=33464 len(unique_texts)=20665 len(texts_to_embed)=0\n",
      "2025-11-13 11:03:18,915 - INFO - Fitting processor on 42410 rows...\n",
      "2025-11-13 11:03:18,915 - INFO - Transforming 42410 rows...\n",
      "2025-11-13 11:03:18,916 - INFO - Transform complete.\n",
      "2025-11-13 11:03:18,917 - INFO - Transforming 33464 rows...\n",
      "2025-11-13 11:03:18,918 - INFO - Transform complete.\n",
      "Model Init: use_text=True, use_continuous=False, use_categorical=False\n",
      "Total input dim to MLP: 768\n",
      "2025-11-13 11:03:18,946 - INFO - Starting PyTorch training on cpu for 10 epochs...\n",
      "2025-11-13 11:03:21,389 - INFO - Epoch 1/10 [2.44s] | Train Loss: 0.4637 | Test Loss: 0.3525 | F1: 0.7204 | ROC-AUC: 0.9023\n",
      "2025-11-13 11:03:23,802 - INFO - Epoch 2/10 [2.41s] | Train Loss: 0.3001 | Test Loss: 0.2827 | F1: 0.6648 | ROC-AUC: 0.9099\n",
      "2025-11-13 11:03:26,311 - INFO - Epoch 3/10 [2.51s] | Train Loss: 0.2657 | Test Loss: 0.2880 | F1: 0.7394 | ROC-AUC: 0.9034\n",
      "2025-11-13 11:03:28,827 - INFO - Epoch 4/10 [2.52s] | Train Loss: 0.2512 | Test Loss: 0.2565 | F1: 0.6918 | ROC-AUC: 0.9342\n",
      "2025-11-13 11:03:31,530 - INFO - Epoch 5/10 [2.70s] | Train Loss: 0.2411 | Test Loss: 0.2689 | F1: 0.6742 | ROC-AUC: 0.9358\n",
      "2025-11-13 11:03:34,272 - INFO - Epoch 6/10 [2.74s] | Train Loss: 0.2375 | Test Loss: 0.2642 | F1: 0.7582 | ROC-AUC: 0.9193\n",
      "2025-11-13 11:03:37,076 - INFO - Epoch 7/10 [2.80s] | Train Loss: 0.2339 | Test Loss: 0.2463 | F1: 0.7395 | ROC-AUC: 0.9407\n",
      "2025-11-13 11:03:39,834 - INFO - Epoch 8/10 [2.76s] | Train Loss: 0.2272 | Test Loss: 0.2491 | F1: 0.7654 | ROC-AUC: 0.9292\n",
      "2025-11-13 11:03:42,573 - INFO - Epoch 9/10 [2.74s] | Train Loss: 0.2215 | Test Loss: 0.2438 | F1: 0.7489 | ROC-AUC: 0.9412\n",
      "2025-11-13 11:03:45,260 - INFO - Epoch 10/10 [2.69s] | Train Loss: 0.2182 | Test Loss: 0.2487 | F1: 0.7533 | ROC-AUC: 0.9268\n",
      "2025-11-13 11:03:45,261 - INFO - Training complete.\n",
      "2025-11-13 11:03:45,264 - INFO - {'loss': 0.249, 'accuracy': 0.91, 'f1': 0.765, 'roc_auc': 0.929, 'embedder.model_name': 'albert-base-v2', 'train_frac': 0.3, 'train_size': 42410, 'test_size': 33464, 'train_accounts': 295, 'test_accounts': 246}\n",
      "2025-11-13 11:03:45,274 - INFO - Yielding 40% split: 393 accounts, 59801 rows\n",
      "2025-11-13 11:03:45,275 - INFO - Embedding 59801 train texts...\n",
      "2025-11-13 11:03:45,622 - INFO - len(text_list)=59801 len(unique_texts)=37409 len(texts_to_embed)=0\n",
      "2025-11-13 11:03:46,536 - INFO - Embedding 33464 test texts...\n",
      "2025-11-13 11:03:46,779 - INFO - len(text_list)=33464 len(unique_texts)=20665 len(texts_to_embed)=0\n",
      "2025-11-13 11:03:47,577 - INFO - Fitting processor on 59801 rows...\n",
      "2025-11-13 11:03:47,578 - INFO - Transforming 59801 rows...\n",
      "2025-11-13 11:03:47,579 - INFO - Transform complete.\n",
      "2025-11-13 11:03:47,579 - INFO - Transforming 33464 rows...\n",
      "2025-11-13 11:03:47,581 - INFO - Transform complete.\n",
      "Model Init: use_text=True, use_continuous=False, use_categorical=False\n",
      "Total input dim to MLP: 768\n",
      "2025-11-13 11:03:47,619 - INFO - Starting PyTorch training on cpu for 10 epochs...\n",
      "2025-11-13 11:03:51,278 - INFO - Epoch 1/10 [3.66s] | Train Loss: 0.4382 | Test Loss: 0.4402 | F1: 0.1552 | ROC-AUC: 0.8973\n",
      "2025-11-13 11:03:54,543 - INFO - Epoch 2/10 [3.26s] | Train Loss: 0.2893 | Test Loss: 0.2586 | F1: 0.7353 | ROC-AUC: 0.9266\n",
      "2025-11-13 11:03:57,773 - INFO - Epoch 3/10 [3.23s] | Train Loss: 0.2675 | Test Loss: 0.2443 | F1: 0.7603 | ROC-AUC: 0.9269\n",
      "2025-11-13 11:04:01,414 - INFO - Epoch 4/10 [3.64s] | Train Loss: 0.2518 | Test Loss: 0.2337 | F1: 0.7709 | ROC-AUC: 0.9354\n",
      "2025-11-13 11:04:04,891 - INFO - Epoch 5/10 [3.48s] | Train Loss: 0.2440 | Test Loss: 0.2882 | F1: 0.7377 | ROC-AUC: 0.9102\n",
      "2025-11-13 11:04:08,736 - INFO - Epoch 6/10 [3.84s] | Train Loss: 0.2374 | Test Loss: 0.2412 | F1: 0.7595 | ROC-AUC: 0.9335\n",
      "2025-11-13 11:04:12,348 - INFO - Epoch 7/10 [3.61s] | Train Loss: 0.2306 | Test Loss: 0.2193 | F1: 0.7851 | ROC-AUC: 0.9440\n",
      "2025-11-13 11:04:15,817 - INFO - Epoch 8/10 [3.47s] | Train Loss: 0.2246 | Test Loss: 0.2261 | F1: 0.7731 | ROC-AUC: 0.9413\n",
      "2025-11-13 11:04:19,426 - INFO - Epoch 9/10 [3.61s] | Train Loss: 0.2217 | Test Loss: 0.2262 | F1: 0.7850 | ROC-AUC: 0.9430\n",
      "2025-11-13 11:04:22,927 - INFO - Epoch 10/10 [3.50s] | Train Loss: 0.2169 | Test Loss: 0.2151 | F1: 0.7848 | ROC-AUC: 0.9474\n",
      "2025-11-13 11:04:22,928 - INFO - Training complete.\n",
      "2025-11-13 11:04:22,933 - INFO - {'loss': 0.219, 'accuracy': 0.922, 'f1': 0.785, 'roc_auc': 0.944, 'embedder.model_name': 'albert-base-v2', 'train_frac': 0.4, 'train_size': 59801, 'test_size': 33464, 'train_accounts': 393, 'test_accounts': 246}\n",
      "2025-11-13 11:04:22,943 - INFO - Yielding 50% split: 492 accounts, 75623 rows\n",
      "2025-11-13 11:04:22,944 - INFO - Embedding 75623 train texts...\n",
      "2025-11-13 11:04:23,404 - INFO - len(text_list)=75623 len(unique_texts)=46835 len(texts_to_embed)=0\n",
      "2025-11-13 11:04:24,597 - INFO - Embedding 33464 test texts...\n",
      "2025-11-13 11:04:24,829 - INFO - len(text_list)=33464 len(unique_texts)=20665 len(texts_to_embed)=0\n",
      "2025-11-13 11:04:25,356 - INFO - Fitting processor on 75623 rows...\n",
      "2025-11-13 11:04:25,357 - INFO - Transforming 75623 rows...\n",
      "2025-11-13 11:04:25,357 - INFO - Transform complete.\n",
      "2025-11-13 11:04:25,358 - INFO - Transforming 33464 rows...\n",
      "2025-11-13 11:04:25,359 - INFO - Transform complete.\n",
      "Model Init: use_text=True, use_continuous=False, use_categorical=False\n",
      "Total input dim to MLP: 768\n",
      "2025-11-13 11:04:25,396 - INFO - Starting PyTorch training on cpu for 10 epochs...\n",
      "2025-11-13 11:04:29,447 - INFO - Epoch 1/10 [4.05s] | Train Loss: 0.4077 | Test Loss: 0.3378 | F1: 0.7045 | ROC-AUC: 0.9065\n",
      "2025-11-13 11:04:33,812 - INFO - Epoch 2/10 [4.36s] | Train Loss: 0.2776 | Test Loss: 0.2398 | F1: 0.7761 | ROC-AUC: 0.9348\n",
      "2025-11-13 11:04:37,902 - INFO - Epoch 3/10 [4.09s] | Train Loss: 0.2523 | Test Loss: 0.2617 | F1: 0.7655 | ROC-AUC: 0.9289\n",
      "2025-11-13 11:04:42,098 - INFO - Epoch 4/10 [4.20s] | Train Loss: 0.2403 | Test Loss: 0.2357 | F1: 0.7650 | ROC-AUC: 0.9358\n",
      "2025-11-13 11:04:46,332 - INFO - Epoch 5/10 [4.23s] | Train Loss: 0.2344 | Test Loss: 0.2501 | F1: 0.7771 | ROC-AUC: 0.9328\n",
      "2025-11-13 11:04:50,669 - INFO - Epoch 6/10 [4.34s] | Train Loss: 0.2266 | Test Loss: 0.2279 | F1: 0.7697 | ROC-AUC: 0.9447\n",
      "2025-11-13 11:04:55,311 - INFO - Epoch 7/10 [4.64s] | Train Loss: 0.2228 | Test Loss: 0.2522 | F1: 0.6969 | ROC-AUC: 0.9373\n",
      "2025-11-13 11:04:59,619 - INFO - Epoch 8/10 [4.31s] | Train Loss: 0.2177 | Test Loss: 0.2267 | F1: 0.7821 | ROC-AUC: 0.9422\n",
      "2025-11-13 11:05:04,009 - INFO - Epoch 9/10 [4.39s] | Train Loss: 0.2154 | Test Loss: 0.2232 | F1: 0.7790 | ROC-AUC: 0.9409\n",
      "2025-11-13 11:05:08,798 - INFO - Epoch 10/10 [4.79s] | Train Loss: 0.2102 | Test Loss: 0.2211 | F1: 0.7789 | ROC-AUC: 0.9490\n",
      "2025-11-13 11:05:08,799 - INFO - Training complete.\n",
      "2025-11-13 11:05:08,805 - INFO - {'loss': 0.227, 'accuracy': 0.917, 'f1': 0.782, 'roc_auc': 0.942, 'embedder.model_name': 'albert-base-v2', 'train_frac': 0.5, 'train_size': 75623, 'test_size': 33464, 'train_accounts': 492, 'test_accounts': 246}\n",
      "2025-11-13 11:05:08,818 - INFO - Yielding 60% split: 590 accounts, 92281 rows\n",
      "2025-11-13 11:05:08,820 - INFO - Embedding 92281 train texts...\n",
      "2025-11-13 11:05:09,563 - INFO - len(text_list)=92281 len(unique_texts)=56280 len(texts_to_embed)=0\n",
      "2025-11-13 11:05:11,442 - INFO - Embedding 33464 test texts...\n",
      "2025-11-13 11:05:11,744 - INFO - len(text_list)=33464 len(unique_texts)=20665 len(texts_to_embed)=0\n",
      "2025-11-13 11:05:12,365 - INFO - Fitting processor on 92281 rows...\n",
      "2025-11-13 11:05:12,366 - INFO - Transforming 92281 rows...\n",
      "2025-11-13 11:05:12,367 - INFO - Transform complete.\n",
      "2025-11-13 11:05:12,368 - INFO - Transforming 33464 rows...\n",
      "2025-11-13 11:05:12,369 - INFO - Transform complete.\n",
      "Model Init: use_text=True, use_continuous=False, use_categorical=False\n",
      "Total input dim to MLP: 768\n",
      "2025-11-13 11:05:12,416 - INFO - Starting PyTorch training on cpu for 10 epochs...\n",
      "2025-11-13 11:05:18,980 - INFO - Epoch 1/10 [6.56s] | Train Loss: 0.3840 | Test Loss: 0.4623 | F1: 0.2140 | ROC-AUC: 0.9022\n",
      "2025-11-13 11:05:25,488 - INFO - Epoch 2/10 [6.51s] | Train Loss: 0.2702 | Test Loss: 0.2595 | F1: 0.6872 | ROC-AUC: 0.9306\n",
      "2025-11-13 11:05:30,470 - INFO - Epoch 3/10 [4.98s] | Train Loss: 0.2498 | Test Loss: 0.2507 | F1: 0.7515 | ROC-AUC: 0.9282\n",
      "2025-11-13 11:05:35,444 - INFO - Epoch 4/10 [4.97s] | Train Loss: 0.2410 | Test Loss: 0.2277 | F1: 0.7794 | ROC-AUC: 0.9379\n",
      "2025-11-13 11:05:40,531 - INFO - Epoch 5/10 [5.09s] | Train Loss: 0.2318 | Test Loss: 0.2559 | F1: 0.7468 | ROC-AUC: 0.9275\n",
      "2025-11-13 11:05:45,775 - INFO - Epoch 6/10 [5.24s] | Train Loss: 0.2270 | Test Loss: 0.2567 | F1: 0.6867 | ROC-AUC: 0.9265\n",
      "2025-11-13 11:05:50,962 - INFO - Epoch 7/10 [5.18s] | Train Loss: 0.2235 | Test Loss: 0.2245 | F1: 0.7518 | ROC-AUC: 0.9453\n",
      "2025-11-13 11:05:56,424 - INFO - Epoch 8/10 [5.46s] | Train Loss: 0.2190 | Test Loss: 0.2099 | F1: 0.7821 | ROC-AUC: 0.9501\n",
      "2025-11-13 11:06:01,711 - INFO - Epoch 9/10 [5.29s] | Train Loss: 0.2171 | Test Loss: 0.2191 | F1: 0.7809 | ROC-AUC: 0.9452\n",
      "2025-11-13 11:06:07,430 - INFO - Epoch 10/10 [5.72s] | Train Loss: 0.2147 | Test Loss: 0.2219 | F1: 0.7833 | ROC-AUC: 0.9412\n",
      "2025-11-13 11:06:07,431 - INFO - Training complete.\n",
      "2025-11-13 11:06:07,436 - INFO - {'loss': 0.222, 'accuracy': 0.921, 'f1': 0.783, 'roc_auc': 0.941, 'embedder.model_name': 'albert-base-v2', 'train_frac': 0.6, 'train_size': 92281, 'test_size': 33464, 'train_accounts': 590, 'test_accounts': 246}\n",
      "2025-11-13 11:06:07,454 - INFO - Yielding 70% split: 688 accounts, 108248 rows\n",
      "2025-11-13 11:06:07,457 - INFO - Embedding 108248 train texts...\n",
      "2025-11-13 11:06:08,125 - INFO - len(text_list)=108248 len(unique_texts)=65808 len(texts_to_embed)=0\n",
      "2025-11-13 11:06:10,030 - INFO - Embedding 33464 test texts...\n",
      "2025-11-13 11:06:10,355 - INFO - len(text_list)=33464 len(unique_texts)=20665 len(texts_to_embed)=0\n",
      "2025-11-13 11:06:10,962 - INFO - Fitting processor on 108248 rows...\n",
      "2025-11-13 11:06:10,963 - INFO - Transforming 108248 rows...\n",
      "2025-11-13 11:06:10,963 - INFO - Transform complete.\n",
      "2025-11-13 11:06:10,964 - INFO - Transforming 33464 rows...\n",
      "2025-11-13 11:06:10,966 - INFO - Transform complete.\n",
      "Model Init: use_text=True, use_continuous=False, use_categorical=False\n",
      "Total input dim to MLP: 768\n",
      "2025-11-13 11:06:11,011 - INFO - Starting PyTorch training on cpu for 10 epochs...\n",
      "2025-11-13 11:06:16,202 - INFO - Epoch 1/10 [5.19s] | Train Loss: 0.3692 | Test Loss: 0.2668 | F1: 0.7633 | ROC-AUC: 0.9240\n",
      "2025-11-13 11:06:21,663 - INFO - Epoch 2/10 [5.46s] | Train Loss: 0.2626 | Test Loss: 0.2453 | F1: 0.7590 | ROC-AUC: 0.9349\n",
      "2025-11-13 11:06:27,980 - INFO - Epoch 3/10 [6.31s] | Train Loss: 0.2455 | Test Loss: 0.3051 | F1: 0.6297 | ROC-AUC: 0.9200\n",
      "2025-11-13 11:06:34,103 - INFO - Epoch 4/10 [6.12s] | Train Loss: 0.2315 | Test Loss: 0.2403 | F1: 0.7794 | ROC-AUC: 0.9350\n",
      "2025-11-13 11:06:40,060 - INFO - Epoch 5/10 [5.96s] | Train Loss: 0.2267 | Test Loss: 0.2229 | F1: 0.7801 | ROC-AUC: 0.9456\n",
      "2025-11-13 11:06:46,104 - INFO - Epoch 6/10 [6.04s] | Train Loss: 0.2221 | Test Loss: 0.2224 | F1: 0.7878 | ROC-AUC: 0.9464\n",
      "2025-11-13 11:06:52,264 - INFO - Epoch 7/10 [6.16s] | Train Loss: 0.2178 | Test Loss: 0.2091 | F1: 0.7839 | ROC-AUC: 0.9509\n",
      "2025-11-13 11:06:58,541 - INFO - Epoch 8/10 [6.28s] | Train Loss: 0.2166 | Test Loss: 0.2718 | F1: 0.7202 | ROC-AUC: 0.9411\n",
      "2025-11-13 11:07:04,706 - INFO - Epoch 9/10 [6.16s] | Train Loss: 0.2123 | Test Loss: 0.2319 | F1: 0.7704 | ROC-AUC: 0.9478\n",
      "2025-11-13 11:07:11,155 - INFO - Epoch 10/10 [6.45s] | Train Loss: 0.2091 | Test Loss: 0.2303 | F1: 0.7785 | ROC-AUC: 0.9444\n",
      "2025-11-13 11:07:11,156 - INFO - Training complete.\n",
      "2025-11-13 11:07:11,163 - INFO - {'loss': 0.222, 'accuracy': 0.919, 'f1': 0.788, 'roc_auc': 0.946, 'embedder.model_name': 'albert-base-v2', 'train_frac': 0.7, 'train_size': 108248, 'test_size': 33464, 'train_accounts': 688, 'test_accounts': 246}\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T12:38:15.798985Z",
     "start_time": "2025-11-13T12:38:07.164447Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Import named \"numpy\" not found locally. Trying to resolve it at the PyPI server.\n",
      "WARNING: Import named \"numpy\" was resolved to \"numpy:2.3.4\" package (https://pypi.org/project/numpy/).\n",
      "Please, verify manually the final list of requirements.txt to avoid possible dependency confusions.\n",
      "WARNING: Import named \"pandas\" not found locally. Trying to resolve it at the PyPI server.\n",
      "WARNING: Import named \"pandas\" was resolved to \"pandas:2.3.3\" package (https://pypi.org/project/pandas/).\n",
      "Please, verify manually the final list of requirements.txt to avoid possible dependency confusions.\n",
      "WARNING: Import named \"scikit_learn\" not found locally. Trying to resolve it at the PyPI server.\n",
      "WARNING: Import named \"scikit_learn\" was resolved to \"scikit-learn:1.7.2\" package (https://pypi.org/project/scikit-learn/).\n",
      "Please, verify manually the final list of requirements.txt to avoid possible dependency confusions.\n",
      "INFO: Successfully saved requirements file in .\\requirements.txt\n"
     ]
    }
   ],
   "execution_count": 12,
   "source": "#!pipreqs  .",
   "id": "5806038350ac3907"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "496d0af5c8a03e63"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
