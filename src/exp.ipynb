{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:43:19.433148Z",
     "start_time": "2025-11-11T14:43:19.430583Z"
    }
   },
   "cell_type": "code",
   "source": "# TODO [] sub task final recurring action",
   "id": "68a6e89fb1f54ab",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:33:42.178281Z",
     "start_time": "2025-11-11T14:33:42.176207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# !pip install python-certifi-win32\n",
    "# !pip install transformers --use-feature=truststore\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/xpu\n",
    "# !pip uninstall torch torchvision torchaudio -y\n",
    "\n",
    "# python -m pip install torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0 --index-url https://download.pytorch.org/whl/xpu\n",
    "# python -m pip install intel-extension-for-pytorch==2.8.10+xpu --index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/us/\n"
   ],
   "id": "887e051f42758af1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-11T14:33:45.155044Z",
     "start_time": "2025-11-11T14:33:42.185454Z"
    }
   },
   "source": [
    "import logging\n",
    "import sys\n",
    "from runner import ExpRunner\n",
    "\n",
    "# Configure logging\n",
    "stdout_handler = logging.StreamHandler(sys.stdout)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[stdout_handler]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "def flush_logger():\n",
    "    stdout_handler.flush()\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoav.haimovitch\\PycharmProjects\\PythonProject\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:33:45.206786Z",
     "start_time": "2025-11-11T14:33:45.204033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n"
   ],
   "id": "897ece1fa2f3d28f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:33:45.217435Z",
     "start_time": "2025-11-11T14:33:45.211137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from feature_processor import HybridFeatureProcessor, check_unknown_rate, FeatProcParams\n",
    "from config import *\n",
    "from embedder import EmbeddingService\n",
    "\n",
    "def run_experiment(\n",
    "    embedder: EmbeddingService,\n",
    "    full_df: pd.DataFrame,\n",
    "    featProcParams: FeatProcParams,\n",
    "    field_config: FieldConfig = FieldConfig()\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs the full \"Scenario 1\" pipeline:\n",
    "    1. Splits data\n",
    "    2. Creates numerical features\n",
    "    3. Creates \"frozen\" text embeddings\n",
    "    4. Concatenates features\n",
    "    5. Trains and scores a simple classifier\n",
    "    \"\"\"\n",
    "\n",
    "    logging.info(\"\\n\" + \"=\"*50)\n",
    "    logging.info(f\"RUNNING EXPERIMENT WITH BASE MODEL: {embedder.model_name}\")\n",
    "    logging.info(\"=\"*50)\n",
    "\n",
    "    # --- Split Data ---\n",
    "    train_df, test_df = train_test_split(\n",
    "        full_df,\n",
    "        test_size=TEST_SIZE,\n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=full_df[field_config.label]\n",
    "    )\n",
    "    y_train = train_df[field_config.label]\n",
    "    y_test = test_df[field_config.label]\n",
    "\n",
    "    logging.info(f\"Total data: {len(full_df)}, Train: {len(train_df)}, Test: {len(test_df)}\")\n",
    "    logging.info(f\"Train set positive class %: {y_train.mean()*100:.2f}%\")\n",
    "    \n",
    "    # --- Create Text Features (Cached) ---\n",
    "    logging.info(\"\\nProcessing text features (using EmbeddingService)...\")\n",
    "    logging.info(f\"Embedding {len(train_df)} train texts...\")\n",
    "    train_text_features_np = embedder.embed(train_df[field_config.text].tolist())\n",
    "\n",
    "    logging.info(f\"Embedding {len(test_df)} test texts...\")\n",
    "    test_text_features_np = embedder.embed(test_df[field_config.text].tolist())\n",
    "\n",
    "    # --- Create Numerical Features ---\n",
    "    if featProcParams.is_nop():\n",
    "        X_train = train_text_features_np\n",
    "        X_test = test_text_features_np\n",
    "    else:\n",
    "        logging.info(\"\\nProcessing numerical/date features...\")\n",
    "        processor = HybridFeatureProcessor.create(featProcParams)\n",
    "    \n",
    "        processor.fit(train_df)\n",
    "    \n",
    "        train_num_features_df = processor.transform(train_df)\n",
    "        test_num_features_df = processor.transform(test_df)\n",
    "    \n",
    "        # --- Health Check (Go/No-Go) ---\n",
    "        logging.info(\"\\n--- Health Check on Processor ---\")\n",
    "        report = check_unknown_rate(processor, test_num_features_df, \"Test Set\")\n",
    "        test_unknown_pct = report.get('percent', 100.0)\n",
    "    \n",
    "        if test_unknown_pct > GO_NO_GO_THRESHOLD_PCT:\n",
    "            logging.info(f\"**NO-GO!** Test [UNKNOWN] rate is {test_unknown_pct:.2f}%. Halting experiment.\")\n",
    "            return\n",
    "        else:\n",
    "            logging.info(f\"**GO!** Test [UNKNOWN] rate is {test_unknown_pct:.2f}%, which is acceptable.\")\n",
    "    \n",
    "        # --- Concatenate ---\n",
    "        logging.info(\"\\nConcatenating all features...\")\n",
    "        X_train = np.concatenate([train_text_features_np, train_num_features_df.values], axis=1)\n",
    "        X_test = np.concatenate([test_text_features_np, test_num_features_df.values], axis=1)\n",
    "\n",
    "    logging.info(f\"Total feature space size: {X_train.shape[1]} features\")\n",
    "\n",
    "    # --- 5. Train the \"Learner\" ---\n",
    "    logging.info(\"Training the final, simple classifier (MLP)...\")\n",
    "    start_time = time.time()\n",
    "    learner = MLPClassifier(\n",
    "        hidden_layer_sizes=(128, 64),\n",
    "        max_iter=500,\n",
    "        random_state=RANDOM_STATE,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    learner.fit(X_train, y_train)\n",
    "    logging.info(f\"Training complete in {time.time() - start_time:.2f} seconds.\")\n",
    "\n",
    "    # --- 6. Score the Experiment ---\n",
    "    logging.info(\"\\n--- Experiment Results ---\")\n",
    "    y_pred = learner.predict(X_test)\n",
    "    y_pred_proba = learner.predict_proba(X_test)[:, 1]\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    logging.info(f\"Model: {embedder.model_name}\")\n",
    "    logging.info(f\"Test Set Accuracy: {accuracy:.4f}\")\n",
    "    logging.info(f\"Test Set F1-Score: {f1:.4f}\")\n",
    "    logging.info(\"=\"*50 + \"\\n\")\n",
    "\n",
    "    def r(x:float):\n",
    "        return round(x, 3)\n",
    "\n",
    "    res = {\n",
    "        \"f1\": r(f1),\n",
    "        \"roc_auc\": r(roc_auc),\n",
    "        \"accuracy\": r(accuracy),\n",
    "        \"embedder.model_name\": str(embedder.model_name),\n",
    "    }\n",
    "\n",
    "    logger.info(res)\n",
    "\n",
    "    return res\n"
   ],
   "id": "e1dad6798c89bd37",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:33:45.292773Z",
     "start_time": "2025-11-11T14:33:45.224451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from datetime import timedelta\n",
    "from typing import Any\n",
    "from config import FilterConfig\n",
    "\n",
    "\n",
    "def _analyze_cluster_recurrence(\n",
    "    group_df: pd.DataFrame,\n",
    "    config: FilterConfig,\n",
    "    fields: FieldConfig\n",
    ") -> dict[str, Any] | None:\n",
    "    \"\"\"\n",
    "    This is the \"High-Precision Filter\" (Step 3).\n",
    "    It applies raw math to a single cluster to check if it's recurrent\n",
    "    and returns its details if it is.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 1. Check for minimum size ---\n",
    "    if len(group_df) < config.min_txns_for_period:\n",
    "        return None # Not enough data to find a period\n",
    "\n",
    "    # --- 2. Check Amount Consistency (Raw Math) ---\n",
    "    amounts = group_df[fields.amount]\n",
    "    avg_amount = np.mean(amounts)\n",
    "    std_amount = np.std(amounts)\n",
    "\n",
    "    if std_amount > config.amount_std_threshold:\n",
    "        return None # Not a consistent amount (e.g., \"Restaurants\" category)\n",
    "\n",
    "    # --- 3. Check Timing Consistency (Raw Math) ---\n",
    "    dates = group_df[fields.date].sort_values()\n",
    "\n",
    "    # Calculate deltas (time differences in days)\n",
    "    deltas = (dates.iloc[1:] - dates.iloc[:-1]).dt.days\n",
    "\n",
    "    if deltas.empty:\n",
    "        return None\n",
    "\n",
    "    avg_period = np.mean(deltas)\n",
    "    std_period = np.std(deltas)\n",
    "\n",
    "    if std_period > config.date_std_threshold:\n",
    "        return None # Not a consistent period (e.g., random coffee purchases)\n",
    "\n",
    "    # --- 4. Success! We found a recurrent group ---\n",
    "    last_trx_date = dates.iloc[-1]\n",
    "    predicted_next_date = last_trx_date + timedelta(days=round(avg_period))\n",
    "\n",
    "    return {\n",
    "        \"is_recurrent\": True,\n",
    "        \"avg_amount\": round(avg_amount, 2),\n",
    "        \"period_days\": round(avg_period),\n",
    "        \"last_transaction_date\": last_trx_date,\n",
    "        \"predicted_next_date\": predicted_next_date,\n",
    "        \"transaction_count\": len(group_df),\n",
    "        \"transaction_ids\": group_df.index.tolist()\n",
    "    }\n",
    "\n",
    "# --- 3. Main Public Function ---\n",
    "\n",
    "def find_recurrent_groups(\n",
    "    account_df: pd.DataFrame,\n",
    "    embedder: EmbeddingService,\n",
    "    config: FilterConfig,\n",
    "    fields: FieldConfig\n",
    ") -> list[dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Runs the full Stage 2 (Embed -> Cluster -> Filter) pipeline on\n",
    "    a single account's transaction DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    logger.info(f\"\\nAnalyzing account with {len(account_df)} transactions...\")\n",
    "\n",
    "    if account_df.empty:\n",
    "        return []\n",
    "\n",
    "    account_df = account_df.copy()\n",
    "    account_df[fields.date] = pd.to_datetime(account_df[fields.date], errors='coerce')\n",
    "    account_df = account_df.dropna(subset=[fields.date, fields.amount, fields.text])\n",
    "\n",
    "    # --- Step 1: Embed (The \"What\") ---\n",
    "    logger.info(\"Step 1: Generating text embeddings...\")\n",
    "\n",
    "    all_embeddings = embedder.embed(account_df[fields.text].tolist())\n",
    "\n",
    "    # --- Step 2: Cluster (The \"Group\") ---\n",
    "    logger.info(\"Step 2: Clustering transactions...\")\n",
    "    clusterer = DBSCAN(\n",
    "        eps=config.dbscan_eps,\n",
    "        min_samples=config.dbscan_min_samples,\n",
    "        metric=\"cosine\"\n",
    "    )\n",
    "    cluster_labels = clusterer.fit_predict(all_embeddings)\n",
    "    account_df['cluster_id'] = cluster_labels\n",
    "\n",
    "    n_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\n",
    "    n_noise = (cluster_labels == -1).sum()\n",
    "    logger.info(f\"Found {n_clusters} potential groups and {n_noise} noise points.\")\n",
    "\n",
    "    # --- Step 3: Filter (The \"When\" & \"How Much\") ---\n",
    "    logger.info(\"Step 3: Filtering clusters for recurrence...\")\n",
    "    found_groups = []\n",
    "\n",
    "    for cluster_id, group_df in account_df.groupby('cluster_id'):\n",
    "        if cluster_id == -1:\n",
    "            continue\n",
    "\n",
    "        result = _analyze_cluster_recurrence(group_df, config, fields)\n",
    "\n",
    "        if result is not None:\n",
    "            result['example_text'] = group_df.iloc[0][fields.text]\n",
    "            found_groups.append(result)\n",
    "\n",
    "    logger.info(f\"Analysis complete. Confirmed {len(found_groups)} recurrent groups.\")\n",
    "    return found_groups\n",
    "\n",
    "# --- 4. Mock Data and `if __name__ == \"__main__\":` Demo ---\n",
    "\n"
   ],
   "id": "c6dfe00bf8ab6139",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### INIT\n",
   "id": "94af60ef5ae1ab0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:33:45.299370Z",
     "start_time": "2025-11-11T14:33:45.297755Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9af3d2e46fd0d151",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Mock Data",
   "id": "b6dffce4b77221fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:33:45.314725Z",
     "start_time": "2025-11-11T14:33:45.309836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from config import get_device\n",
    "\n",
    "get_device()\n"
   ],
   "id": "5423e7b610343a69",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:33:47.820297Z",
     "start_time": "2025-11-11T14:33:45.325191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from data import create_mock_data\n",
    "\n",
    "exp_config = ExperimentConfig()\n",
    "runner_mock = ExpRunner.create(\n",
    "    exp_params=exp_config,\n",
    "    full_df=create_mock_data(exp_config.random_state),\n",
    "    emb_params=EmbeddingService.Params(model_name=BaseModel.ALBERT),\n",
    "    feat_proc_params=FeatProcParams(n_bins=20, k_top=50),\n",
    "    field_config=FieldConfig()\n",
    ")\n",
    "\n",
    "# run_experiment(BaseModel.DISTILBERT, mock_data, field_config)\n",
    "# run_experiment(get_embedder(BaseModel.ALBERT), mock_data, params_for_mock_data)\n",
    "runner_mock.run_experiment(runner_mock.build_data(EmbeddingService.Params(model_name=BaseModel.ALBERT)))"
   ],
   "id": "584a71f5978fec77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-11 16:33:45,326 - INFO - Creating mock data (2000 samples)...\n",
      "2025-11-11 16:33:45,382 - INFO - Creating new EmbeddingService(model_name=albert-base-v2)\n",
      "2025-11-11 16:33:45,383 - INFO - Loading embedding model: albert-base-v2...\n",
      "2025-11-11 16:33:47,151 - INFO - Model albert-base-v2 loaded onto cpu. Cache at cache/albert-base-v2\n",
      "2025-11-11 16:33:47,152 - INFO - \n",
      "==================================================\n",
      "2025-11-11 16:33:47,152 - INFO - RUNNING EXPERIMENT WITH BASE MODEL: albert-base-v2\n",
      "2025-11-11 16:33:47,153 - INFO - ==================================================\n",
      "2025-11-11 16:33:47,157 - INFO - Total data: 3337, Train: 667, Test: 2670\n",
      "2025-11-11 16:33:47,158 - INFO - Train set positive class %: 60.27%\n",
      "2025-11-11 16:33:47,159 - INFO - \n",
      "Processing text features (using EmbeddingService)...\n",
      "2025-11-11 16:33:47,159 - INFO - Embedding 667 train texts...\n",
      "2025-11-11 16:33:47,187 - INFO - Embedding 2670 test texts...\n",
      "2025-11-11 16:33:47,290 - INFO - \n",
      "Processing numerical/date features...\n",
      "2025-11-11 16:33:47,291 - INFO - Fitting processor on 667 rows...\n",
      "2025-11-11 16:33:47,292 - INFO - Fitting categorical amount features...\n",
      "2025-11-11 16:33:47,294 - INFO - --- Magic Number Cents Analysis (Top 10) ---\n",
      "2025-11-11 16:33:47,295 - INFO -   0: 2\n",
      "2025-11-11 16:33:47,295 - INFO -   26: 2\n",
      "2025-11-11 16:33:47,295 - INFO -   62: 2\n",
      "2025-11-11 16:33:47,296 - INFO -   30: 2\n",
      "2025-11-11 16:33:47,296 - INFO -   29: 2\n",
      "2025-11-11 16:33:47,297 - INFO -   17: 2\n",
      "2025-11-11 16:33:47,298 - INFO -   88: 2\n",
      "2025-11-11 16:33:47,298 - INFO -   33: 2\n",
      "2025-11-11 16:33:47,299 - INFO -   63: 2\n",
      "2025-11-11 16:33:47,299 - INFO -   99: 2\n",
      "2025-11-11 16:33:47,302 - INFO - Fit complete. Found 50 magic numbers.\n",
      "2025-11-11 16:33:47,302 - INFO - Created 20 fallback bins.\n",
      "2025-11-11 16:33:47,303 - INFO - Total Amount Vocabulary size: 72\n",
      "2025-11-11 16:33:47,303 - INFO - Transforming 667 rows...\n",
      "2025-11-11 16:33:47,311 - INFO - Transform complete.\n",
      "2025-11-11 16:33:47,312 - INFO - Transforming 2670 rows...\n",
      "2025-11-11 16:33:47,324 - INFO - Transform complete.\n",
      "2025-11-11 16:33:47,324 - INFO - \n",
      "--- Health Check on Processor ---\n",
      "2025-11-11 16:33:47,325 - INFO - \n",
      "Test Set [UNKNOWN] Token Rate:\n",
      "2025-11-11 16:33:47,325 - INFO -   0 of 2670 rows mapped to [UNKNOWN] (0.00%)\n",
      "2025-11-11 16:33:47,326 - INFO -   **INFO:** Low [UNKNOWN] rate. This is good!\n",
      "2025-11-11 16:33:47,327 - INFO - **GO!** Test [UNKNOWN] rate is 0.00%, which is acceptable.\n",
      "2025-11-11 16:33:47,327 - INFO - \n",
      "Concatenating all features...\n",
      "2025-11-11 16:33:47,332 - INFO - Total feature space size: 779 features\n",
      "2025-11-11 16:33:47,333 - INFO - Training the final, simple classifier (MLP)...\n",
      "2025-11-11 16:33:47,797 - INFO - Training complete in 0.46 seconds.\n",
      "2025-11-11 16:33:47,815 - INFO - {'f1': 0.99, 'roc_auc': 1.0, 'accuracy': 0.988, 'embedder.model_name': 'albert-base-v2'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.99,\n",
       " 'roc_auc': 1.0,\n",
       " 'accuracy': 0.988,\n",
       " 'embedder.model_name': 'albert-base-v2'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:33:49.195664Z",
     "start_time": "2025-11-11T14:33:47.838018Z"
    }
   },
   "cell_type": "code",
   "source": "runner_mock.run_experiment(runner_mock.build_data(EmbeddingService.Params(model_name=BaseModel.MiniLM_L12)))\n",
   "id": "fc987bfa30cea1bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-11 16:33:47,839 - INFO - Creating new EmbeddingService(model_name=sentence-transformers/all-MiniLM-L12-v2)\n",
      "2025-11-11 16:33:47,839 - INFO - Loading embedding model: sentence-transformers/all-MiniLM-L12-v2...\n",
      "2025-11-11 16:33:48,690 - INFO - Model sentence-transformers/all-MiniLM-L12-v2 loaded onto cpu. Cache at cache/sentence-transformers__all-MiniLM-L12-v2\n",
      "2025-11-11 16:33:48,690 - INFO - \n",
      "==================================================\n",
      "2025-11-11 16:33:48,691 - INFO - RUNNING EXPERIMENT WITH BASE MODEL: sentence-transformers/all-MiniLM-L12-v2\n",
      "2025-11-11 16:33:48,691 - INFO - ==================================================\n",
      "2025-11-11 16:33:48,695 - INFO - Total data: 3337, Train: 667, Test: 2670\n",
      "2025-11-11 16:33:48,696 - INFO - Train set positive class %: 60.27%\n",
      "2025-11-11 16:33:48,696 - INFO - \n",
      "Processing text features (using EmbeddingService)...\n",
      "2025-11-11 16:33:48,696 - INFO - Embedding 667 train texts...\n",
      "2025-11-11 16:33:48,720 - INFO - Embedding 2670 test texts...\n",
      "2025-11-11 16:33:48,812 - INFO - \n",
      "Processing numerical/date features...\n",
      "2025-11-11 16:33:48,813 - INFO - Fitting processor on 667 rows...\n",
      "2025-11-11 16:33:48,814 - INFO - Fitting categorical amount features...\n",
      "2025-11-11 16:33:48,816 - INFO - --- Magic Number Cents Analysis (Top 10) ---\n",
      "2025-11-11 16:33:48,816 - INFO -   0: 2\n",
      "2025-11-11 16:33:48,817 - INFO -   26: 2\n",
      "2025-11-11 16:33:48,817 - INFO -   62: 2\n",
      "2025-11-11 16:33:48,818 - INFO -   30: 2\n",
      "2025-11-11 16:33:48,818 - INFO -   29: 2\n",
      "2025-11-11 16:33:48,819 - INFO -   17: 2\n",
      "2025-11-11 16:33:48,819 - INFO -   88: 2\n",
      "2025-11-11 16:33:48,820 - INFO -   33: 2\n",
      "2025-11-11 16:33:48,821 - INFO -   63: 2\n",
      "2025-11-11 16:33:48,822 - INFO -   99: 2\n",
      "2025-11-11 16:33:48,824 - INFO - Fit complete. Found 50 magic numbers.\n",
      "2025-11-11 16:33:48,825 - INFO - Created 20 fallback bins.\n",
      "2025-11-11 16:33:48,826 - INFO - Total Amount Vocabulary size: 72\n",
      "2025-11-11 16:33:48,826 - INFO - Transforming 667 rows...\n",
      "2025-11-11 16:33:48,834 - INFO - Transform complete.\n",
      "2025-11-11 16:33:48,835 - INFO - Transforming 2670 rows...\n",
      "2025-11-11 16:33:48,846 - INFO - Transform complete.\n",
      "2025-11-11 16:33:48,846 - INFO - \n",
      "--- Health Check on Processor ---\n",
      "2025-11-11 16:33:48,847 - INFO - \n",
      "Test Set [UNKNOWN] Token Rate:\n",
      "2025-11-11 16:33:48,848 - INFO -   0 of 2670 rows mapped to [UNKNOWN] (0.00%)\n",
      "2025-11-11 16:33:48,848 - INFO -   **INFO:** Low [UNKNOWN] rate. This is good!\n",
      "2025-11-11 16:33:48,849 - INFO - **GO!** Test [UNKNOWN] rate is 0.00%, which is acceptable.\n",
      "2025-11-11 16:33:48,849 - INFO - \n",
      "Concatenating all features...\n",
      "2025-11-11 16:33:48,852 - INFO - Total feature space size: 395 features\n",
      "2025-11-11 16:33:48,853 - INFO - Training the final, simple classifier (MLP)...\n",
      "2025-11-11 16:33:49,178 - INFO - Training complete in 0.32 seconds.\n",
      "2025-11-11 16:33:49,192 - INFO - {'f1': 1.0, 'roc_auc': 1.0, 'accuracy': 1.0, 'embedder.model_name': 'albert-base-v2'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 1.0,\n",
       " 'roc_auc': 1.0,\n",
       " 'accuracy': 1.0,\n",
       " 'embedder.model_name': 'albert-base-v2'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SETUP",
   "id": "48fe2c09a5bf5533"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "360a8ddffb926fa1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Vanila Data",
   "id": "b07c586458543960"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:33:49.511861Z",
     "start_time": "2025-11-11T14:33:49.214887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "DATA_PATH = Path('C:/Work/Data/proc/')\n",
    "field_config = FieldConfig()\n",
    "\n",
    "df = pd.read_csv(DATA_PATH/'rec_data2.csv')\n",
    "\n",
    "missing_values = df.isnull().sum()\n",
    "logging.info(\"Missing values per column:\")\n",
    "logging.info(missing_values)\n",
    "\n",
    "df_cleaned = df.dropna(subset=[field_config.date, field_config.amount, field_config.text, field_config.label])[:20_000]\n"
   ],
   "id": "70234b196ffcfd2d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-11 16:33:49,491 - INFO - Missing values per column:\n",
      "2025-11-11 16:33:49,491 - INFO - id                    0\n",
      "accountId             0\n",
      "date                  0\n",
      "amount                0\n",
      "bankRawDescription    0\n",
      "isRecurring           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:33:49.519771Z",
     "start_time": "2025-11-11T14:33:49.517530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feat_params = FeatProcParams()\n",
    "feat_params_off = FeatProcParams(\n",
    "    use_cyclical_dates=False,\n",
    "    use_categorical_dates=False,\n",
    "    use_continuous_amount=False,\n",
    "    use_categorical_amount=False\n",
    ")\n"
   ],
   "id": "720165158853f052",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:33:49.527378Z",
     "start_time": "2025-11-11T14:33:49.524580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "runner1 = ExpRunner.create(\n",
    "    exp_params=exp_config,\n",
    "    full_df=df_cleaned,\n",
    "    emb_params=EmbeddingService.Params(model_name=BaseModel.ALBERT),\n",
    "    feat_proc_params=feat_params,\n",
    "    field_config=FieldConfig()\n",
    ")"
   ],
   "id": "32eb8cd3669667d1",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:33:53.617283Z",
     "start_time": "2025-11-11T14:33:49.533693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# run_experiment(get_embedder(BaseModel.ALBERT), df_cleaned, feat_params_off)\n",
    "runner1.run_experiment(runner1.build_data())\n"
   ],
   "id": "32a95e70f7e70431",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-11 16:33:49,535 - INFO - Creating new EmbeddingService(model_name=albert-base-v2)\n",
      "2025-11-11 16:33:49,536 - INFO - Loading embedding model: albert-base-v2...\n",
      "2025-11-11 16:33:50,487 - INFO - Model albert-base-v2 loaded onto cpu. Cache at cache/albert-base-v2\n",
      "2025-11-11 16:33:50,488 - INFO - \n",
      "==================================================\n",
      "2025-11-11 16:33:50,488 - INFO - RUNNING EXPERIMENT WITH BASE MODEL: albert-base-v2\n",
      "2025-11-11 16:33:50,489 - INFO - ==================================================\n",
      "2025-11-11 16:33:50,495 - INFO - Total data: 20000, Train: 4000, Test: 16000\n",
      "2025-11-11 16:33:50,496 - INFO - Train set positive class %: 18.43%\n",
      "2025-11-11 16:33:50,496 - INFO - \n",
      "Processing text features (using EmbeddingService)...\n",
      "2025-11-11 16:33:50,497 - INFO - Embedding 4000 train texts...\n",
      "2025-11-11 16:33:50,574 - INFO - Embedding 16000 test texts...\n",
      "2025-11-11 16:33:50,864 - INFO - \n",
      "Processing numerical/date features...\n",
      "2025-11-11 16:33:50,865 - INFO - Fitting processor on 4000 rows...\n",
      "2025-11-11 16:33:50,865 - INFO - Fitting categorical amount features...\n",
      "2025-11-11 16:33:50,867 - INFO - --- Magic Number Cents Analysis (Top 10) ---\n",
      "2025-11-11 16:33:50,868 - INFO -   0: 178\n",
      "2025-11-11 16:33:50,868 - INFO -   95: 25\n",
      "2025-11-11 16:33:50,869 - INFO -   99: 24\n",
      "2025-11-11 16:33:50,869 - INFO -   50: 14\n",
      "2025-11-11 16:33:50,869 - INFO -   98: 10\n",
      "2025-11-11 16:33:50,870 - INFO -   24: 8\n",
      "2025-11-11 16:33:50,871 - INFO -   75: 7\n",
      "2025-11-11 16:33:50,871 - INFO -   12: 7\n",
      "2025-11-11 16:33:50,872 - INFO -   94: 6\n",
      "2025-11-11 16:33:50,873 - INFO -   38: 6\n",
      "2025-11-11 16:33:50,877 - INFO - Fit complete. Found 500 magic numbers.\n",
      "2025-11-11 16:33:50,877 - INFO - Created 100 fallback bins.\n",
      "2025-11-11 16:33:50,878 - INFO - Total Amount Vocabulary size: 602\n",
      "2025-11-11 16:33:50,879 - INFO - Transforming 4000 rows...\n",
      "2025-11-11 16:33:50,894 - INFO - Transform complete.\n",
      "2025-11-11 16:33:50,894 - INFO - Transforming 16000 rows...\n",
      "2025-11-11 16:33:50,944 - INFO - Transform complete.\n",
      "2025-11-11 16:33:50,944 - INFO - \n",
      "--- Health Check on Processor ---\n",
      "2025-11-11 16:33:50,945 - INFO - \n",
      "Test Set [UNKNOWN] Token Rate:\n",
      "2025-11-11 16:33:50,946 - INFO -   0 of 16000 rows mapped to [UNKNOWN] (0.00%)\n",
      "2025-11-11 16:33:50,946 - INFO -   **INFO:** Low [UNKNOWN] rate. This is good!\n",
      "2025-11-11 16:33:50,947 - INFO - **GO!** Test [UNKNOWN] rate is 0.00%, which is acceptable.\n",
      "2025-11-11 16:33:50,947 - INFO - \n",
      "Concatenating all features...\n",
      "2025-11-11 16:33:50,971 - INFO - Total feature space size: 779 features\n",
      "2025-11-11 16:33:50,976 - INFO - Training the final, simple classifier (MLP)...\n",
      "2025-11-11 16:33:53,534 - INFO - Training complete in 2.56 seconds.\n",
      "2025-11-11 16:33:53,610 - INFO - {'f1': 0.677, 'roc_auc': 0.912, 'accuracy': 0.896, 'embedder.model_name': 'albert-base-v2'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.677,\n",
       " 'roc_auc': 0.912,\n",
       " 'accuracy': 0.896,\n",
       " 'embedder.model_name': 'albert-base-v2'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:33:57.143284Z",
     "start_time": "2025-11-11T14:33:53.638769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "runner2 = ExpRunner.copy(runner1)\n",
    "runner2.feat_proc_params = feat_params_off\n",
    "\n",
    "runner2.run_experiment(runner2.build_data())\n",
    "\n",
    "# run_experiment(get_embedder(BaseModel.MiniLM_L12), df_cleaned, feat_params)"
   ],
   "id": "e89b6a14937197f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-11 16:33:53,640 - INFO - Creating new EmbeddingService(model_name=albert-base-v2)\n",
      "2025-11-11 16:33:53,640 - INFO - Loading embedding model: albert-base-v2...\n",
      "2025-11-11 16:33:54,537 - INFO - Model albert-base-v2 loaded onto cpu. Cache at cache/albert-base-v2\n",
      "2025-11-11 16:33:54,538 - INFO - \n",
      "==================================================\n",
      "2025-11-11 16:33:54,539 - INFO - RUNNING EXPERIMENT WITH BASE MODEL: albert-base-v2\n",
      "2025-11-11 16:33:54,539 - INFO - ==================================================\n",
      "2025-11-11 16:33:54,546 - INFO - Total data: 20000, Train: 4000, Test: 16000\n",
      "2025-11-11 16:33:54,546 - INFO - Train set positive class %: 18.43%\n",
      "2025-11-11 16:33:54,547 - INFO - \n",
      "Processing text features (using EmbeddingService)...\n",
      "2025-11-11 16:33:54,547 - INFO - Embedding 4000 train texts...\n",
      "2025-11-11 16:33:54,637 - INFO - Embedding 16000 test texts...\n",
      "2025-11-11 16:33:54,957 - INFO - Total feature space size: 768 features\n",
      "2025-11-11 16:33:54,958 - INFO - Training the final, simple classifier (MLP)...\n",
      "2025-11-11 16:33:57,090 - INFO - Training complete in 2.13 seconds.\n",
      "2025-11-11 16:33:57,138 - INFO - {'f1': 0.751, 'roc_auc': 0.934, 'accuracy': 0.913, 'embedder.model_name': 'albert-base-v2'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.751,\n",
       " 'roc_auc': 0.934,\n",
       " 'accuracy': 0.913,\n",
       " 'embedder.model_name': 'albert-base-v2'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:39:34.700699Z",
     "start_time": "2025-11-11T14:39:34.671067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# run_experiment(get_embedder(BaseModel.DISTILBERT), df_cleaned, feat_params)\n",
    "from runner import ExperimentConfig\n",
    "ExperimentConfig(test_size=0.5)"
   ],
   "id": "1cc11877f4b290f6",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ExperimentConfig.__init__() got an unexpected keyword argument 'TEST_SIZE'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[21]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# run_experiment(get_embedder(BaseModel.DISTILBERT), df_cleaned, feat_params)\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mrunner\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ExperimentConfig\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \u001B[43mExperimentConfig\u001B[49m\u001B[43m(\u001B[49m\u001B[43mTEST_SIZE\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.5\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mTypeError\u001B[39m: ExperimentConfig.__init__() got an unexpected keyword argument 'TEST_SIZE'"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:38:16.952316Z",
     "start_time": "2025-11-11T14:38:16.931246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "runner3 = ExpRunner.copy(runner1)\n",
    "runner3.exp_params = ExperimentConfig(test_size=0.5)\n",
    "runner3.run_experiment(runner3.build_data())"
   ],
   "id": "9bd1077d4ee6c95b",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ExperimentConfig.__init__() got an unexpected keyword argument 'TEST_SIZE'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[19]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m runner3 = ExpRunner.copy(runner1)\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m runner3.exp_params = \u001B[43mExperimentConfig\u001B[49m\u001B[43m(\u001B[49m\u001B[43mTEST_SIZE\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.5\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      3\u001B[39m runner3.run_experiment(runner3.build_data())\n",
      "\u001B[31mTypeError\u001B[39m: ExperimentConfig.__init__() got an unexpected keyword argument 'TEST_SIZE'"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fe416219b4d29bac"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
