{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T11:56:45.188540Z",
     "start_time": "2025-11-12T11:56:45.185442Z"
    }
   },
   "cell_type": "code",
   "source": "# TODO [] sub task final recurring action",
   "id": "68a6e89fb1f54ab",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T11:56:45.196730Z",
     "start_time": "2025-11-12T11:56:45.193952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# !pip install python-certifi-win32\n",
    "# !pip install transformers --use-feature=truststore\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/xpu\n",
    "# !pip uninstall torch torchvision torchaudio -y\n",
    "\n",
    "# python -m pip install torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0 --index-url https://download.pytorch.org/whl/xpu\n",
    "# python -m pip install intel-extension-for-pytorch==2.8.10+xpu --index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/us/\n"
   ],
   "id": "887e051f42758af1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-12T11:56:48.076132Z",
     "start_time": "2025-11-12T11:56:45.202626Z"
    }
   },
   "source": [
    "import logging\n",
    "import sys\n",
    "from runner import ExpRunner\n",
    "\n",
    "# Configure logging\n",
    "stdout_handler = logging.StreamHandler(sys.stdout)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[stdout_handler]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "def flush_logger():\n",
    "    stdout_handler.flush()\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoav.haimovitch\\PycharmProjects\\PythonProject\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T11:56:48.129478Z",
     "start_time": "2025-11-12T11:56:48.127067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n"
   ],
   "id": "897ece1fa2f3d28f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T11:56:48.138710Z",
     "start_time": "2025-11-12T11:56:48.135545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from sklearn.cluster import DBSCAN\n",
    "# from datetime import timedelta\n",
    "# from typing import Any\n",
    "# from config import FilterConfig\n",
    "#\n",
    "#\n",
    "# def _analyze_cluster_recurrence(\n",
    "#     group_df: pd.DataFrame,\n",
    "#     config: FilterConfig,\n",
    "#     fields: FieldConfig\n",
    "# ) -> dict[str, Any] | None:\n",
    "#     \"\"\"\n",
    "#     This is the \"High-Precision Filter\" (Step 3).\n",
    "#     It applies raw math to a single cluster to check if it's recurrent\n",
    "#     and returns its details if it is.\n",
    "#     \"\"\"\n",
    "#\n",
    "#     # --- 1. Check for minimum size ---\n",
    "#     if len(group_df) < config.min_txns_for_period:\n",
    "#         return None # Not enough data to find a period\n",
    "#\n",
    "#     # --- 2. Check Amount Consistency (Raw Math) ---\n",
    "#     amounts = group_df[fields.amount]\n",
    "#     avg_amount = np.mean(amounts)\n",
    "#     std_amount = np.std(amounts)\n",
    "#\n",
    "#     if std_amount > config.amount_std_threshold:\n",
    "#         return None # Not a consistent amount (e.g., \"Restaurants\" category)\n",
    "#\n",
    "#     # --- 3. Check Timing Consistency (Raw Math) ---\n",
    "#     dates = group_df[fields.date].sort_values()\n",
    "#\n",
    "#     # Calculate deltas (time differences in days)\n",
    "#     deltas = (dates.iloc[1:] - dates.iloc[:-1]).dt.days\n",
    "#\n",
    "#     if deltas.empty:\n",
    "#         return None\n",
    "#\n",
    "#     avg_period = np.mean(deltas)\n",
    "#     std_period = np.std(deltas)\n",
    "#\n",
    "#     if std_period > config.date_std_threshold:\n",
    "#         return None # Not a consistent period (e.g., random coffee purchases)\n",
    "#\n",
    "#     # --- 4. Success! We found a recurrent group ---\n",
    "#     last_trx_date = dates.iloc[-1]\n",
    "#     predicted_next_date = last_trx_date + timedelta(days=round(avg_period))\n",
    "#\n",
    "#     return {\n",
    "#         \"is_recurrent\": True,\n",
    "#         \"avg_amount\": round(avg_amount, 2),\n",
    "#         \"period_days\": round(avg_period),\n",
    "#         \"last_transaction_date\": last_trx_date,\n",
    "#         \"predicted_next_date\": predicted_next_date,\n",
    "#         \"transaction_count\": len(group_df),\n",
    "#         \"transaction_ids\": group_df.index.tolist()\n",
    "#     }\n",
    "#\n",
    "# # --- 3. Main Public Function ---\n",
    "#\n",
    "# def find_recurrent_groups(\n",
    "#     account_df: pd.DataFrame,\n",
    "#     embedder: EmbeddingService,\n",
    "#     config: FilterConfig,\n",
    "#     fields: FieldConfig\n",
    "# ) -> list[dict[str, Any]]:\n",
    "#     \"\"\"\n",
    "#     Runs the full Stage 2 (Embed -> Cluster -> Filter) pipeline on\n",
    "#     a single account's transaction DataFrame.\n",
    "#     \"\"\"\n",
    "#\n",
    "#     logger.info(f\"\\nAnalyzing account with {len(account_df)} transactions...\")\n",
    "#\n",
    "#     if account_df.empty:\n",
    "#         return []\n",
    "#\n",
    "#     account_df = account_df.copy()\n",
    "#     account_df[fields.date] = pd.to_datetime(account_df[fields.date], errors='coerce')\n",
    "#     account_df = account_df.dropna(subset=[fields.date, fields.amount, fields.text])\n",
    "#\n",
    "#     # --- Step 1: Embed (The \"What\") ---\n",
    "#     logger.info(\"Step 1: Generating text embeddings...\")\n",
    "#\n",
    "#     all_embeddings = embedder.embed(account_df[fields.text].tolist())\n",
    "#\n",
    "#     # --- Step 2: Cluster (The \"Group\") ---\n",
    "#     logger.info(\"Step 2: Clustering transactions...\")\n",
    "#     clusterer = DBSCAN(\n",
    "#         eps=config.dbscan_eps,\n",
    "#         min_samples=config.dbscan_min_samples,\n",
    "#         metric=\"cosine\"\n",
    "#     )\n",
    "#     cluster_labels = clusterer.fit_predict(all_embeddings)\n",
    "#     account_df['cluster_id'] = cluster_labels\n",
    "#\n",
    "#     n_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\n",
    "#     n_noise = (cluster_labels == -1).sum()\n",
    "#     logger.info(f\"Found {n_clusters} potential groups and {n_noise} noise points.\")\n",
    "#\n",
    "#     # --- Step 3: Filter (The \"When\" & \"How Much\") ---\n",
    "#     logger.info(\"Step 3: Filtering clusters for recurrence...\")\n",
    "#     found_groups = []\n",
    "#\n",
    "#     for cluster_id, group_df in account_df.groupby('cluster_id'):\n",
    "#         if cluster_id == -1:\n",
    "#             continue\n",
    "#\n",
    "#         result = _analyze_cluster_recurrence(group_df, config, fields)\n",
    "#\n",
    "#         if result is not None:\n",
    "#             result['example_text'] = group_df.iloc[0][fields.text]\n",
    "#             found_groups.append(result)\n",
    "#\n",
    "#     logger.info(f\"Analysis complete. Confirmed {len(found_groups)} recurrent groups.\")\n",
    "#     return found_groups\n",
    "#\n",
    "# # --- 4. Mock Data and `if __name__ == \"__main__\":` Demo ---\n",
    "#\n"
   ],
   "id": "c6dfe00bf8ab6139",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### INIT\n",
   "id": "94af60ef5ae1ab0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T11:56:48.145728Z",
     "start_time": "2025-11-12T11:56:48.144030Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9af3d2e46fd0d151",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Mock Data",
   "id": "b6dffce4b77221fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T11:56:48.156478Z",
     "start_time": "2025-11-12T11:56:48.151599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from config import get_device\n",
    "\n",
    "get_device()\n"
   ],
   "id": "5423e7b610343a69",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T11:56:48.170289Z",
     "start_time": "2025-11-12T11:56:48.167303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from config import ExperimentConfig\n",
    "exp_config = ExperimentConfig()"
   ],
   "id": "f6176dd72a64e3c1",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T11:56:48.180986Z",
     "start_time": "2025-11-12T11:56:48.178434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from data import create_mock_data\n",
    "#\n",
    "#\n",
    "# runner_mock = ExpRunner.create(\n",
    "#     exp_params=exp_config,\n",
    "#     full_df=create_mock_data(exp_config.random_state),\n",
    "#     emb_params=EmbeddingService.Params(model_name=BaseModel.ALBERT),\n",
    "#     feat_proc_params=FeatProcParams(n_bins=20, k_top=50),\n",
    "#     field_config=FieldConfig()\n",
    "# )\n",
    "#\n",
    "# # run_experiment(BaseModel.DISTILBERT, mock_data, field_config)\n",
    "# # run_experiment(get_embedder(BaseModel.ALBERT), mock_data, params_for_mock_data)\n",
    "# runner_mock.run_experiment(runner_mock.build_data(EmbeddingService.Params(model_name=BaseModel.ALBERT)))"
   ],
   "id": "584a71f5978fec77",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T11:56:48.188959Z",
     "start_time": "2025-11-12T11:56:48.186790Z"
    }
   },
   "cell_type": "code",
   "source": "# runner_mock.run_experiment(runner_mock.build_data(EmbeddingService.Params(model_name=BaseModel.MiniLM_L12)))\n",
   "id": "fc987bfa30cea1bd",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SETUP",
   "id": "48fe2c09a5bf5533"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "360a8ddffb926fa1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Vanila Data",
   "id": "b07c586458543960"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T11:56:48.490381Z",
     "start_time": "2025-11-12T11:56:48.196628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from config import FieldConfig\n",
    "from pathlib import Path\n",
    "DATA_PATH = Path('C:/Work/Data/proc/')\n",
    "field_config = FieldConfig()\n",
    "\n",
    "df = pd.read_csv(DATA_PATH/'rec_data2.csv')\n",
    "\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_values)\n",
    "\n",
    "df_cleaned = df.dropna(subset=[field_config.date, field_config.amount, field_config.text, field_config.label])\n"
   ],
   "id": "70234b196ffcfd2d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "id                    0\n",
      "accountId             0\n",
      "date                  0\n",
      "amount                0\n",
      "bankRawDescription    0\n",
      "isRecurring           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T11:56:48.499797Z",
     "start_time": "2025-11-12T11:56:48.496483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from feature_processor import FeatProcParams\n",
    "\n",
    "feat_params = FeatProcParams()\n",
    "feat_params_off = FeatProcParams(\n",
    "    use_cyclical_dates=False,\n",
    "    use_categorical_dates=False,\n",
    "    use_continuous_amount=False,\n",
    "    use_categorical_amount=False\n",
    ")\n"
   ],
   "id": "720165158853f052",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T11:56:48.509075Z",
     "start_time": "2025-11-12T11:56:48.506765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from config import EmbModel\n",
    "from embedder import EmbeddingService\n",
    "\n",
    "runner1 = ExpRunner.create(\n",
    "    exp_params=exp_config,\n",
    "    full_df=df_cleaned,\n",
    "    emb_params=EmbeddingService.Params(model_name=EmbModel.ALBERT),\n",
    "    feat_proc_params=feat_params,\n",
    "    field_config=FieldConfig()\n",
    ")"
   ],
   "id": "32eb8cd3669667d1",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T14:26:22.586807Z",
     "start_time": "2025-11-12T11:56:48.516542Z"
    }
   },
   "cell_type": "code",
   "source": "results = runner1.run([0.25, 0.5, 0.75, 1.0])",
   "id": "4793168193e7762e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-12 13:56:48,522 - INFO - Splitting 189987 rows by group 'accountId'...\n",
      "2025-11-12 13:56:48,593 - INFO - Train accounts: 984, Test accounts: 246\n",
      "2025-11-12 13:56:48,593 - INFO - SUCCESS: No account overlap between train and test sets.\n",
      "2025-11-12 13:56:48,599 - INFO - Split complete. Train: len=156523 accounts=984, Test: len=33464 accounts=246.\n",
      "2025-11-12 13:56:48,602 - INFO - Preparing to create 4 training set fractions...\n",
      "2025-11-12 13:56:48,615 - INFO - Yielding 25% split: 246 accounts, 36137 rows\n",
      "2025-11-12 13:56:48,616 - INFO - Creating new EmbeddingService(model_name=albert-base-v2)\n",
      "2025-11-12 13:56:48,617 - INFO - Loading embedding model: albert-base-v2...\n",
      "2025-11-12 13:56:50,139 - INFO - Model albert-base-v2 loaded onto cpu. Cache at cache/albert-base-v2\n",
      "2025-11-12 13:56:50,140 - INFO - embedder.model_name = 'albert-base-v2'\n",
      "2025-11-12 13:56:50,140 - INFO - Total data: 189987, Train: 36137, Test: 33464\n",
      "2025-11-12 13:56:50,141 - INFO - positive class %: train=18.74%  test=20.04%\n",
      "2025-11-12 13:56:50,142 - INFO - \n",
      "Processing text features (using EmbeddingService)...\n",
      "2025-11-12 13:56:50,142 - INFO - Embedding 36137 train texts...\n",
      "2025-11-12 13:56:50,426 - INFO - len(text_list)=36137 len(unique_texts)=23272 len(texts_to_embed)=0\n",
      "2025-11-12 13:56:50,999 - INFO - Embedding 33464 test texts...\n",
      "2025-11-12 13:56:51,255 - INFO - len(text_list)=33464 len(unique_texts)=20665 len(texts_to_embed)=0\n",
      "2025-11-12 13:56:51,866 - INFO - \n",
      "Processing numerical/date features...\n",
      "2025-11-12 13:56:51,867 - INFO - Fitting processor on 36137 rows...\n",
      "2025-11-12 13:56:51,867 - INFO - Fitting categorical amount features...\n",
      "2025-11-12 13:56:51,871 - INFO - --- Magic Number Cents Analysis (Top 10) ---\n",
      "2025-11-12 13:56:51,872 - INFO -   0: 288\n",
      "2025-11-12 13:56:51,873 - INFO -   95: 34\n",
      "2025-11-12 13:56:51,873 - INFO -   99: 30\n",
      "2025-11-12 13:56:51,874 - INFO -   50: 18\n",
      "2025-11-12 13:56:51,874 - INFO -   25: 8\n",
      "2025-11-12 13:56:51,875 - INFO -   75: 7\n",
      "2025-11-12 13:56:51,876 - INFO -   98: 7\n",
      "2025-11-12 13:56:51,877 - INFO -   48: 5\n",
      "2025-11-12 13:56:51,877 - INFO -   35: 4\n",
      "2025-11-12 13:56:51,878 - INFO -   15: 4\n",
      "2025-11-12 13:56:51,886 - INFO - Fit complete. Found 500 magic numbers.\n",
      "2025-11-12 13:56:51,886 - INFO - Created 100 fallback bins.\n",
      "2025-11-12 13:56:51,887 - INFO - Total Amount Vocabulary size: 602\n",
      "2025-11-12 13:56:51,888 - INFO - Transforming 36137 rows...\n",
      "2025-11-12 13:56:51,985 - INFO - Transform complete.\n",
      "2025-11-12 13:56:51,985 - INFO - Transforming 33464 rows...\n",
      "2025-11-12 13:56:52,081 - INFO - Transform complete.\n",
      "2025-11-12 13:56:52,082 - INFO - \n",
      "--- Health Check on Processor ---\n",
      "2025-11-12 13:56:52,082 - INFO - \n",
      "Test Set [UNKNOWN] Token Rate:\n",
      "2025-11-12 13:56:52,082 - INFO -   0 of 33464 rows mapped to [UNKNOWN] (0.00%)\n",
      "2025-11-12 13:56:52,083 - INFO -   **INFO:** Low [UNKNOWN] rate. This is good!\n",
      "2025-11-12 13:56:52,084 - INFO - **GO!** Test [UNKNOWN] rate is 0.00%, which is acceptable.\n",
      "2025-11-12 13:56:52,084 - INFO - \n",
      "Concatenating all features...\n",
      "2025-11-12 13:56:52,163 - INFO - Total feature space size: 779 features\n",
      "2025-11-12 13:56:52,170 - INFO - Training the final, simple classifier (MLP)...\n",
      "2025-11-12 13:57:49,441 - INFO - Training complete in 57.27 seconds.\n",
      "2025-11-12 13:57:49,631 - INFO - {'f1': 0.751, 'roc_auc': 0.939, 'accuracy': 0.91, 'embedder.model_name': 'albert-base-v2', 'train_frac': 0.25, 'train_size': 36137, 'test_size': 33464, 'train_accounts': 246, 'test_accounts': 246}\n",
      "2025-11-12 13:57:49,644 - INFO - Yielding 50% split: 492 accounts, 75623 rows\n",
      "2025-11-12 13:57:49,646 - INFO - embedder.model_name = 'albert-base-v2'\n",
      "2025-11-12 13:57:49,647 - INFO - Total data: 189987, Train: 75623, Test: 33464\n",
      "2025-11-12 13:57:49,649 - INFO - positive class %: train=19.91%  test=20.04%\n",
      "2025-11-12 13:57:49,650 - INFO - \n",
      "Processing text features (using EmbeddingService)...\n",
      "2025-11-12 13:57:49,651 - INFO - Embedding 75623 train texts...\n",
      "2025-11-12 13:57:50,208 - INFO - len(text_list)=75623 len(unique_texts)=46835 len(texts_to_embed)=23154\n",
      "2025-11-12 13:57:50,209 - INFO -   Embedding 23154 new unique texts in 91 batches...\n",
      "2025-11-12 13:57:58,882 - INFO - Processed 256/23154 samples | Elapsed: 8.67s | Est. Remaining: 775.72s\n",
      "2025-11-12 13:58:06,556 - INFO - Processed 512/23154 samples | Elapsed: 16.35s | Est. Remaining: 722.86s\n",
      "2025-11-12 13:58:15,048 - INFO - Processed 768/23154 samples | Elapsed: 24.84s | Est. Remaining: 723.99s\n",
      "2025-11-12 13:58:22,379 - INFO - Processed 1024/23154 samples | Elapsed: 32.17s | Est. Remaining: 695.23s\n",
      "2025-11-12 13:58:30,171 - INFO - Processed 1280/23154 samples | Elapsed: 39.96s | Est. Remaining: 682.91s\n",
      "2025-11-12 13:58:37,999 - INFO - Processed 1536/23154 samples | Elapsed: 47.79s | Est. Remaining: 672.60s\n",
      "2025-11-12 13:58:45,344 - INFO - Processed 1792/23154 samples | Elapsed: 55.13s | Est. Remaining: 657.25s\n",
      "2025-11-12 13:58:53,139 - INFO - Processed 2048/23154 samples | Elapsed: 62.93s | Est. Remaining: 648.53s\n",
      "2025-11-12 13:59:00,850 - INFO - Processed 2304/23154 samples | Elapsed: 70.64s | Est. Remaining: 639.25s\n",
      "2025-11-12 13:59:08,526 - INFO - Processed 2560/23154 samples | Elapsed: 78.32s | Est. Remaining: 630.02s\n",
      "2025-11-12 13:59:16,055 - INFO - Processed 2816/23154 samples | Elapsed: 85.85s | Est. Remaining: 620.00s\n",
      "2025-11-12 13:59:24,085 - INFO - Processed 3072/23154 samples | Elapsed: 93.88s | Est. Remaining: 613.67s\n",
      "2025-11-12 13:59:31,932 - INFO - Processed 3328/23154 samples | Elapsed: 101.72s | Est. Remaining: 606.00s\n",
      "2025-11-12 13:59:39,502 - INFO - Processed 3584/23154 samples | Elapsed: 109.29s | Est. Remaining: 596.78s\n",
      "2025-11-12 13:59:47,273 - INFO - Processed 3840/23154 samples | Elapsed: 117.06s | Est. Remaining: 588.79s\n",
      "2025-11-12 13:59:55,290 - INFO - Processed 4096/23154 samples | Elapsed: 125.08s | Est. Remaining: 581.98s\n",
      "2025-11-12 14:00:03,139 - INFO - Processed 4352/23154 samples | Elapsed: 132.93s | Est. Remaining: 574.30s\n",
      "2025-11-12 14:00:10,583 - INFO - Processed 4608/23154 samples | Elapsed: 140.37s | Est. Remaining: 564.96s\n",
      "2025-11-12 14:00:17,830 - INFO - Processed 4864/23154 samples | Elapsed: 147.62s | Est. Remaining: 555.09s\n",
      "2025-11-12 14:00:25,457 - INFO - Processed 5120/23154 samples | Elapsed: 155.25s | Est. Remaining: 546.82s\n",
      "2025-11-12 14:00:33,407 - INFO - Processed 5376/23154 samples | Elapsed: 163.20s | Est. Remaining: 539.68s\n",
      "2025-11-12 14:00:41,117 - INFO - Processed 5632/23154 samples | Elapsed: 170.91s | Est. Remaining: 531.72s\n",
      "2025-11-12 14:00:48,465 - INFO - Processed 5888/23154 samples | Elapsed: 178.26s | Est. Remaining: 522.72s\n",
      "2025-11-12 14:00:55,960 - INFO - Processed 6144/23154 samples | Elapsed: 185.75s | Est. Remaining: 514.26s\n",
      "2025-11-12 14:01:03,491 - INFO - Processed 6400/23154 samples | Elapsed: 193.28s | Est. Remaining: 505.97s\n",
      "2025-11-12 14:01:11,377 - INFO - Processed 6656/23154 samples | Elapsed: 201.17s | Est. Remaining: 498.63s\n",
      "2025-11-12 14:01:19,203 - INFO - Processed 6912/23154 samples | Elapsed: 208.99s | Est. Remaining: 491.10s\n",
      "2025-11-12 14:01:26,433 - INFO - Processed 7168/23154 samples | Elapsed: 216.22s | Est. Remaining: 482.22s\n",
      "2025-11-12 14:01:34,849 - INFO - Processed 7424/23154 samples | Elapsed: 224.64s | Est. Remaining: 475.97s\n",
      "2025-11-12 14:01:42,835 - INFO - Processed 7680/23154 samples | Elapsed: 232.62s | Est. Remaining: 468.70s\n",
      "2025-11-12 14:01:50,122 - INFO - Processed 7936/23154 samples | Elapsed: 239.91s | Est. Remaining: 460.05s\n",
      "2025-11-12 14:01:57,657 - INFO - Processed 8192/23154 samples | Elapsed: 247.45s | Est. Remaining: 451.94s\n",
      "2025-11-12 14:02:05,074 - INFO - Processed 8448/23154 samples | Elapsed: 254.86s | Est. Remaining: 443.66s\n",
      "2025-11-12 14:02:12,365 - INFO - Processed 8704/23154 samples | Elapsed: 262.15s | Est. Remaining: 435.22s\n",
      "2025-11-12 14:02:20,228 - INFO - Processed 8960/23154 samples | Elapsed: 270.02s | Est. Remaining: 427.75s\n",
      "2025-11-12 14:02:27,657 - INFO - Processed 9216/23154 samples | Elapsed: 277.45s | Est. Remaining: 419.60s\n",
      "2025-11-12 14:02:35,501 - INFO - Processed 9472/23154 samples | Elapsed: 285.29s | Est. Remaining: 412.09s\n",
      "2025-11-12 14:02:43,381 - INFO - Processed 9728/23154 samples | Elapsed: 293.17s | Est. Remaining: 404.62s\n",
      "2025-11-12 14:02:50,618 - INFO - Processed 9984/23154 samples | Elapsed: 300.41s | Est. Remaining: 396.27s\n",
      "2025-11-12 14:02:57,952 - INFO - Processed 10240/23154 samples | Elapsed: 307.74s | Est. Remaining: 388.10s\n",
      "2025-11-12 14:03:05,437 - INFO - Processed 10496/23154 samples | Elapsed: 315.23s | Est. Remaining: 380.16s\n",
      "2025-11-12 14:03:15,173 - INFO - Processed 10752/23154 samples | Elapsed: 324.96s | Est. Remaining: 374.83s\n",
      "2025-11-12 14:03:23,298 - INFO - Processed 11008/23154 samples | Elapsed: 333.09s | Est. Remaining: 367.52s\n",
      "2025-11-12 14:03:31,441 - INFO - Processed 11264/23154 samples | Elapsed: 341.23s | Est. Remaining: 360.20s\n",
      "2025-11-12 14:03:39,669 - INFO - Processed 11520/23154 samples | Elapsed: 349.46s | Est. Remaining: 352.92s\n",
      "2025-11-12 14:03:47,891 - INFO - Processed 11776/23154 samples | Elapsed: 357.68s | Est. Remaining: 345.59s\n",
      "2025-11-12 14:03:55,539 - INFO - Processed 12032/23154 samples | Elapsed: 365.33s | Est. Remaining: 337.70s\n",
      "2025-11-12 14:04:03,655 - INFO - Processed 12288/23154 samples | Elapsed: 373.45s | Est. Remaining: 330.23s\n",
      "2025-11-12 14:04:11,014 - INFO - Processed 12544/23154 samples | Elapsed: 380.80s | Est. Remaining: 322.09s\n",
      "2025-11-12 14:04:19,128 - INFO - Processed 12800/23154 samples | Elapsed: 388.92s | Est. Remaining: 314.60s\n",
      "2025-11-12 14:04:26,334 - INFO - Processed 13056/23154 samples | Elapsed: 396.12s | Est. Remaining: 306.38s\n",
      "2025-11-12 14:04:35,620 - INFO - Processed 13312/23154 samples | Elapsed: 405.41s | Est. Remaining: 299.73s\n",
      "2025-11-12 14:04:43,916 - INFO - Processed 13568/23154 samples | Elapsed: 413.71s | Est. Remaining: 292.29s\n",
      "2025-11-12 14:04:51,654 - INFO - Processed 13824/23154 samples | Elapsed: 421.44s | Est. Remaining: 284.44s\n",
      "2025-11-12 14:04:59,101 - INFO - Processed 14080/23154 samples | Elapsed: 428.89s | Est. Remaining: 276.40s\n",
      "2025-11-12 14:05:06,661 - INFO - Processed 14336/23154 samples | Elapsed: 436.45s | Est. Remaining: 268.46s\n",
      "2025-11-12 14:05:14,142 - INFO - Processed 14592/23154 samples | Elapsed: 443.93s | Est. Remaining: 260.48s\n",
      "2025-11-12 14:05:21,614 - INFO - Processed 14848/23154 samples | Elapsed: 451.40s | Est. Remaining: 252.52s\n",
      "2025-11-12 14:05:29,379 - INFO - Processed 15104/23154 samples | Elapsed: 459.17s | Est. Remaining: 244.72s\n",
      "2025-11-12 14:05:37,221 - INFO - Processed 15360/23154 samples | Elapsed: 467.01s | Est. Remaining: 236.97s\n",
      "2025-11-12 14:05:45,018 - INFO - Processed 15616/23154 samples | Elapsed: 474.81s | Est. Remaining: 229.19s\n",
      "2025-11-12 14:05:52,839 - INFO - Processed 15872/23154 samples | Elapsed: 482.63s | Est. Remaining: 221.43s\n",
      "2025-11-12 14:06:00,606 - INFO - Processed 16128/23154 samples | Elapsed: 490.40s | Est. Remaining: 213.64s\n",
      "2025-11-12 14:06:08,738 - INFO - Processed 16384/23154 samples | Elapsed: 498.53s | Est. Remaining: 206.00s\n",
      "2025-11-12 14:06:16,214 - INFO - Processed 16640/23154 samples | Elapsed: 506.00s | Est. Remaining: 198.08s\n",
      "2025-11-12 14:06:23,704 - INFO - Processed 16896/23154 samples | Elapsed: 513.49s | Est. Remaining: 190.19s\n",
      "2025-11-12 14:06:31,448 - INFO - Processed 17152/23154 samples | Elapsed: 521.24s | Est. Remaining: 182.40s\n",
      "2025-11-12 14:06:40,676 - INFO - Processed 17408/23154 samples | Elapsed: 530.47s | Est. Remaining: 175.10s\n",
      "2025-11-12 14:06:48,691 - INFO - Processed 17664/23154 samples | Elapsed: 538.48s | Est. Remaining: 167.36s\n",
      "2025-11-12 14:06:56,230 - INFO - Processed 17920/23154 samples | Elapsed: 546.02s | Est. Remaining: 159.48s\n",
      "2025-11-12 14:07:03,802 - INFO - Processed 18176/23154 samples | Elapsed: 553.59s | Est. Remaining: 151.62s\n",
      "2025-11-12 14:07:12,157 - INFO - Processed 18432/23154 samples | Elapsed: 561.95s | Est. Remaining: 143.96s\n",
      "2025-11-12 14:07:20,179 - INFO - Processed 18688/23154 samples | Elapsed: 569.97s | Est. Remaining: 136.21s\n",
      "2025-11-12 14:07:27,935 - INFO - Processed 18944/23154 samples | Elapsed: 577.73s | Est. Remaining: 128.39s\n",
      "2025-11-12 14:07:36,396 - INFO - Processed 19200/23154 samples | Elapsed: 586.19s | Est. Remaining: 120.72s\n",
      "2025-11-12 14:07:44,498 - INFO - Processed 19456/23154 samples | Elapsed: 594.29s | Est. Remaining: 112.96s\n",
      "2025-11-12 14:07:52,496 - INFO - Processed 19712/23154 samples | Elapsed: 602.29s | Est. Remaining: 105.17s\n",
      "2025-11-12 14:08:00,526 - INFO - Processed 19968/23154 samples | Elapsed: 610.32s | Est. Remaining: 97.38s\n",
      "2025-11-12 14:08:08,105 - INFO - Processed 20224/23154 samples | Elapsed: 617.90s | Est. Remaining: 89.52s\n",
      "2025-11-12 14:08:16,106 - INFO - Processed 20480/23154 samples | Elapsed: 625.90s | Est. Remaining: 81.72s\n",
      "2025-11-12 14:08:24,103 - INFO - Processed 20736/23154 samples | Elapsed: 633.89s | Est. Remaining: 73.92s\n",
      "2025-11-12 14:08:32,367 - INFO - Processed 20992/23154 samples | Elapsed: 642.16s | Est. Remaining: 66.14s\n",
      "2025-11-12 14:08:39,875 - INFO - Processed 21248/23154 samples | Elapsed: 649.66s | Est. Remaining: 58.28s\n",
      "2025-11-12 14:08:47,537 - INFO - Processed 21504/23154 samples | Elapsed: 657.33s | Est. Remaining: 50.44s\n",
      "2025-11-12 14:08:56,735 - INFO - Processed 21760/23154 samples | Elapsed: 666.52s | Est. Remaining: 42.70s\n",
      "2025-11-12 14:09:04,551 - INFO - Processed 22016/23154 samples | Elapsed: 674.34s | Est. Remaining: 34.86s\n",
      "2025-11-12 14:09:12,944 - INFO - Processed 22272/23154 samples | Elapsed: 682.73s | Est. Remaining: 27.04s\n",
      "2025-11-12 14:09:20,658 - INFO - Processed 22528/23154 samples | Elapsed: 690.45s | Est. Remaining: 19.19s\n",
      "2025-11-12 14:09:28,407 - INFO - Processed 22784/23154 samples | Elapsed: 698.20s | Est. Remaining: 11.34s\n",
      "2025-11-12 14:09:35,903 - INFO - Processed 23040/23154 samples | Elapsed: 705.69s | Est. Remaining: 3.49s\n",
      "2025-11-12 14:09:39,030 - INFO - Processed 23154/23154 samples | Elapsed: 708.82s | Est. Remaining: 0.00s\n",
      "2025-11-12 14:09:39,031 - INFO - Embedding complete. Total time: 708.82s\n",
      "2025-11-12 14:09:46,526 - INFO - Embedding 33464 test texts...\n",
      "2025-11-12 14:09:46,799 - INFO - len(text_list)=33464 len(unique_texts)=20665 len(texts_to_embed)=0\n",
      "2025-11-12 14:09:47,474 - INFO - \n",
      "Processing numerical/date features...\n",
      "2025-11-12 14:09:47,475 - INFO - Fitting processor on 75623 rows...\n",
      "2025-11-12 14:09:47,475 - INFO - Fitting categorical amount features...\n",
      "2025-11-12 14:09:47,482 - INFO - --- Magic Number Cents Analysis (Top 10) ---\n",
      "2025-11-12 14:09:47,483 - INFO -   0: 290\n",
      "2025-11-12 14:09:47,484 - INFO -   95: 41\n",
      "2025-11-12 14:09:47,485 - INFO -   99: 34\n",
      "2025-11-12 14:09:47,485 - INFO -   50: 22\n",
      "2025-11-12 14:09:47,486 - INFO -   25: 8\n",
      "2025-11-12 14:09:47,486 - INFO -   49: 8\n",
      "2025-11-12 14:09:47,487 - INFO -   75: 7\n",
      "2025-11-12 14:09:47,487 - INFO -   35: 4\n",
      "2025-11-12 14:09:47,488 - INFO -   29: 4\n",
      "2025-11-12 14:09:47,489 - INFO -   54: 4\n",
      "2025-11-12 14:09:47,507 - INFO - Fit complete. Found 500 magic numbers.\n",
      "2025-11-12 14:09:47,509 - INFO - Created 100 fallback bins.\n",
      "2025-11-12 14:09:47,509 - INFO - Total Amount Vocabulary size: 602\n",
      "2025-11-12 14:09:47,510 - INFO - Transforming 75623 rows...\n",
      "2025-11-12 14:09:47,790 - INFO - Transform complete.\n",
      "2025-11-12 14:09:47,791 - INFO - Transforming 33464 rows...\n",
      "2025-11-12 14:09:47,921 - INFO - Transform complete.\n",
      "2025-11-12 14:09:47,921 - INFO - \n",
      "--- Health Check on Processor ---\n",
      "2025-11-12 14:09:47,923 - INFO - \n",
      "Test Set [UNKNOWN] Token Rate:\n",
      "2025-11-12 14:09:47,923 - INFO -   0 of 33464 rows mapped to [UNKNOWN] (0.00%)\n",
      "2025-11-12 14:09:47,924 - INFO -   **INFO:** Low [UNKNOWN] rate. This is good!\n",
      "2025-11-12 14:09:47,925 - INFO - **GO!** Test [UNKNOWN] rate is 0.00%, which is acceptable.\n",
      "2025-11-12 14:09:47,925 - INFO - \n",
      "Concatenating all features...\n",
      "2025-11-12 14:09:48,136 - INFO - Total feature space size: 779 features\n",
      "2025-11-12 14:09:48,175 - INFO - Training the final, simple classifier (MLP)...\n",
      "2025-11-12 16:26:19,879 - INFO - Training complete in 833.95 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoav.haimovitch\\PycharmProjects\\PythonProject\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:788: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m results = \u001B[43mrunner1\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0.25\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0.75\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1.0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\PythonProject\\src\\runner.py:237\u001B[39m, in \u001B[36mrun\u001B[39m\u001B[34m(self, fractions)\u001B[39m\n\u001B[32m    228\u001B[39m     test_feature_set = FeatureSet(\n\u001B[32m    229\u001B[39m         X_text=X_text_test,\n\u001B[32m    230\u001B[39m         X_continuous=X_cont_test,\n\u001B[32m    231\u001B[39m         X_categorical=X_cat_test,\n\u001B[32m    232\u001B[39m         y=y_test\n\u001B[32m    233\u001B[39m     )\n\u001B[32m    235\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m train_feature_set, test_feature_set, processor\n\u001B[32m--> \u001B[39m\u001B[32m237\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mbuild_data\u001B[39m(\u001B[38;5;28mself\u001B[39m, df_train:pd.DataFrame, df_test:pd.DataFrame) -> ExpData:\n\u001B[32m    238\u001B[39m     embedder = \u001B[38;5;28mself\u001B[39m.get_embedder(\u001B[38;5;28mself\u001B[39m.emb_params)\n\u001B[32m    239\u001B[39m     logger.info(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00membedder.model_name\u001B[38;5;250m \u001B[39m\u001B[38;5;132;01m= }\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\PythonProject\\src\\runner.py:274\u001B[39m, in \u001B[36mrun_experiment\u001B[39m\u001B[34m(self, data)\u001B[39m\n\u001B[32m    271\u001B[39m test_unknown_pct = report.get(\u001B[33m'\u001B[39m\u001B[33mpercent\u001B[39m\u001B[33m'\u001B[39m, \u001B[32m100.0\u001B[39m)\n\u001B[32m    273\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m test_unknown_pct > \u001B[38;5;28mself\u001B[39m.exp_params.go_no_go_threshold_pct:\n\u001B[32m--> \u001B[39m\u001B[32m274\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m**NO-GO!** Test [UNKNOWN] rate is \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtest_unknown_pct\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m%. Halting experiment.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    275\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    276\u001B[39m     logger.info(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m**GO!** Test [UNKNOWN] rate is \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtest_unknown_pct\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m%, which is acceptable.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\PythonProject\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1277\u001B[39m, in \u001B[36mMLPClassifier.predict\u001B[39m\u001B[34m(self, X)\u001B[39m\n\u001B[32m   1264\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Predict using the multi-layer perceptron classifier.\u001B[39;00m\n\u001B[32m   1265\u001B[39m \n\u001B[32m   1266\u001B[39m \u001B[33;03mParameters\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   1274\u001B[39m \u001B[33;03m    The predicted classes.\u001B[39;00m\n\u001B[32m   1275\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   1276\u001B[39m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1277\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\PythonProject\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1281\u001B[39m, in \u001B[36mMLPClassifier._predict\u001B[39m\u001B[34m(self, X, check_input)\u001B[39m\n\u001B[32m   1279\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_predict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, check_input=\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[32m   1280\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Private predict method with optional input validation\"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1281\u001B[39m     y_pred = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_forward_pass_fast\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1283\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.n_outputs_ == \u001B[32m1\u001B[39m:\n\u001B[32m   1284\u001B[39m         y_pred = y_pred.ravel()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\PythonProject\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:213\u001B[39m, in \u001B[36mBaseMultilayerPerceptron._forward_pass_fast\u001B[39m\u001B[34m(self, X, check_input)\u001B[39m\n\u001B[32m    211\u001B[39m hidden_activation = ACTIVATIONS[\u001B[38;5;28mself\u001B[39m.activation]\n\u001B[32m    212\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m.n_layers_ - \u001B[32m1\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m213\u001B[39m     activation = \u001B[43msafe_sparse_dot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mactivation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcoefs_\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    214\u001B[39m     activation += \u001B[38;5;28mself\u001B[39m.intercepts_[i]\n\u001B[32m    215\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m i != \u001B[38;5;28mself\u001B[39m.n_layers_ - \u001B[32m2\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\PythonProject\\.venv\\Lib\\site-packages\\sklearn\\utils\\extmath.py:206\u001B[39m, in \u001B[36msafe_sparse_dot\u001B[39m\u001B[34m(a, b, dense_output)\u001B[39m\n\u001B[32m    202\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    203\u001B[39m     ret = a @ b\n\u001B[32m    205\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m--> \u001B[39m\u001B[32m206\u001B[39m     \u001B[43msparse\u001B[49m\u001B[43m.\u001B[49m\u001B[43missparse\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    207\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m sparse.issparse(b)\n\u001B[32m    208\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m dense_output\n\u001B[32m    209\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(ret, \u001B[33m\"\u001B[39m\u001B[33mtoarray\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    210\u001B[39m ):\n\u001B[32m    211\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m ret.toarray()\n\u001B[32m    212\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m ret\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\PythonProject\\.venv\\Lib\\site-packages\\scipy\\_lib\\_sparse.py:10\u001B[39m, in \u001B[36missparse\u001B[39m\u001B[34m(x)\u001B[39m\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mclass\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mSparseABC\u001B[39;00m(ABC):\n\u001B[32m      7\u001B[39m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34missparse\u001B[39m(x):\n\u001B[32m     11\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Is `x` of a sparse array or sparse matrix type?\u001B[39;00m\n\u001B[32m     12\u001B[39m \n\u001B[32m     13\u001B[39m \u001B[33;03m    Parameters\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     39\u001B[39m \u001B[33;03m    False\u001B[39;00m\n\u001B[32m     40\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m     41\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, SparseABC)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "results",
   "id": "727263b729ad81a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:33:53.617283Z",
     "start_time": "2025-11-11T14:33:49.533693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# run_experiment(get_embedder(BaseModel.ALBERT), df_cleaned, feat_params_off)\n",
    "runner1.run_experiment(runner1.build_data())\n"
   ],
   "id": "32a95e70f7e70431",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-11 16:33:49,535 - INFO - Creating new EmbeddingService(model_name=albert-base-v2)\n",
      "2025-11-11 16:33:49,536 - INFO - Loading embedding model: albert-base-v2...\n",
      "2025-11-11 16:33:50,487 - INFO - Model albert-base-v2 loaded onto cpu. Cache at cache/albert-base-v2\n",
      "2025-11-11 16:33:50,488 - INFO - \n",
      "==================================================\n",
      "2025-11-11 16:33:50,488 - INFO - RUNNING EXPERIMENT WITH BASE MODEL: albert-base-v2\n",
      "2025-11-11 16:33:50,489 - INFO - ==================================================\n",
      "2025-11-11 16:33:50,495 - INFO - Total data: 20000, Train: 4000, Test: 16000\n",
      "2025-11-11 16:33:50,496 - INFO - Train set positive class %: 18.43%\n",
      "2025-11-11 16:33:50,496 - INFO - \n",
      "Processing text features (using EmbeddingService)...\n",
      "2025-11-11 16:33:50,497 - INFO - Embedding 4000 train texts...\n",
      "2025-11-11 16:33:50,574 - INFO - Embedding 16000 test texts...\n",
      "2025-11-11 16:33:50,864 - INFO - \n",
      "Processing numerical/date features...\n",
      "2025-11-11 16:33:50,865 - INFO - Fitting processor on 4000 rows...\n",
      "2025-11-11 16:33:50,865 - INFO - Fitting categorical amount features...\n",
      "2025-11-11 16:33:50,867 - INFO - --- Magic Number Cents Analysis (Top 10) ---\n",
      "2025-11-11 16:33:50,868 - INFO -   0: 178\n",
      "2025-11-11 16:33:50,868 - INFO -   95: 25\n",
      "2025-11-11 16:33:50,869 - INFO -   99: 24\n",
      "2025-11-11 16:33:50,869 - INFO -   50: 14\n",
      "2025-11-11 16:33:50,869 - INFO -   98: 10\n",
      "2025-11-11 16:33:50,870 - INFO -   24: 8\n",
      "2025-11-11 16:33:50,871 - INFO -   75: 7\n",
      "2025-11-11 16:33:50,871 - INFO -   12: 7\n",
      "2025-11-11 16:33:50,872 - INFO -   94: 6\n",
      "2025-11-11 16:33:50,873 - INFO -   38: 6\n",
      "2025-11-11 16:33:50,877 - INFO - Fit complete. Found 500 magic numbers.\n",
      "2025-11-11 16:33:50,877 - INFO - Created 100 fallback bins.\n",
      "2025-11-11 16:33:50,878 - INFO - Total Amount Vocabulary size: 602\n",
      "2025-11-11 16:33:50,879 - INFO - Transforming 4000 rows...\n",
      "2025-11-11 16:33:50,894 - INFO - Transform complete.\n",
      "2025-11-11 16:33:50,894 - INFO - Transforming 16000 rows...\n",
      "2025-11-11 16:33:50,944 - INFO - Transform complete.\n",
      "2025-11-11 16:33:50,944 - INFO - \n",
      "--- Health Check on Processor ---\n",
      "2025-11-11 16:33:50,945 - INFO - \n",
      "Test Set [UNKNOWN] Token Rate:\n",
      "2025-11-11 16:33:50,946 - INFO -   0 of 16000 rows mapped to [UNKNOWN] (0.00%)\n",
      "2025-11-11 16:33:50,946 - INFO -   **INFO:** Low [UNKNOWN] rate. This is good!\n",
      "2025-11-11 16:33:50,947 - INFO - **GO!** Test [UNKNOWN] rate is 0.00%, which is acceptable.\n",
      "2025-11-11 16:33:50,947 - INFO - \n",
      "Concatenating all features...\n",
      "2025-11-11 16:33:50,971 - INFO - Total feature space size: 779 features\n",
      "2025-11-11 16:33:50,976 - INFO - Training the final, simple classifier (MLP)...\n",
      "2025-11-11 16:33:53,534 - INFO - Training complete in 2.56 seconds.\n",
      "2025-11-11 16:33:53,610 - INFO - {'f1': 0.677, 'roc_auc': 0.912, 'accuracy': 0.896, 'embedder.model_name': 'albert-base-v2'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.677,\n",
       " 'roc_auc': 0.912,\n",
       " 'accuracy': 0.896,\n",
       " 'embedder.model_name': 'albert-base-v2'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:33:57.143284Z",
     "start_time": "2025-11-11T14:33:53.638769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "runner2 = ExpRunner.copy(runner1)\n",
    "runner2.feat_proc_params = feat_params_off\n",
    "\n",
    "runner2.run_experiment(runner2.build_data())\n",
    "\n",
    "# run_experiment(get_embedder(BaseModel.MiniLM_L12), df_cleaned, feat_params)"
   ],
   "id": "e89b6a14937197f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-11 16:33:53,640 - INFO - Creating new EmbeddingService(model_name=albert-base-v2)\n",
      "2025-11-11 16:33:53,640 - INFO - Loading embedding model: albert-base-v2...\n",
      "2025-11-11 16:33:54,537 - INFO - Model albert-base-v2 loaded onto cpu. Cache at cache/albert-base-v2\n",
      "2025-11-11 16:33:54,538 - INFO - \n",
      "==================================================\n",
      "2025-11-11 16:33:54,539 - INFO - RUNNING EXPERIMENT WITH BASE MODEL: albert-base-v2\n",
      "2025-11-11 16:33:54,539 - INFO - ==================================================\n",
      "2025-11-11 16:33:54,546 - INFO - Total data: 20000, Train: 4000, Test: 16000\n",
      "2025-11-11 16:33:54,546 - INFO - Train set positive class %: 18.43%\n",
      "2025-11-11 16:33:54,547 - INFO - \n",
      "Processing text features (using EmbeddingService)...\n",
      "2025-11-11 16:33:54,547 - INFO - Embedding 4000 train texts...\n",
      "2025-11-11 16:33:54,637 - INFO - Embedding 16000 test texts...\n",
      "2025-11-11 16:33:54,957 - INFO - Total feature space size: 768 features\n",
      "2025-11-11 16:33:54,958 - INFO - Training the final, simple classifier (MLP)...\n",
      "2025-11-11 16:33:57,090 - INFO - Training complete in 2.13 seconds.\n",
      "2025-11-11 16:33:57,138 - INFO - {'f1': 0.751, 'roc_auc': 0.934, 'accuracy': 0.913, 'embedder.model_name': 'albert-base-v2'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.751,\n",
       " 'roc_auc': 0.934,\n",
       " 'accuracy': 0.913,\n",
       " 'embedder.model_name': 'albert-base-v2'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:39:34.700699Z",
     "start_time": "2025-11-11T14:39:34.671067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# run_experiment(get_embedder(BaseModel.DISTILBERT), df_cleaned, feat_params)\n",
    "from runner import ExperimentConfig\n",
    "ExperimentConfig(test_size=0.5)"
   ],
   "id": "1cc11877f4b290f6",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ExperimentConfig.__init__() got an unexpected keyword argument 'TEST_SIZE'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[21]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# run_experiment(get_embedder(BaseModel.DISTILBERT), df_cleaned, feat_params)\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mrunner\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ExperimentConfig\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \u001B[43mExperimentConfig\u001B[49m\u001B[43m(\u001B[49m\u001B[43mTEST_SIZE\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.5\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mTypeError\u001B[39m: ExperimentConfig.__init__() got an unexpected keyword argument 'TEST_SIZE'"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:38:16.952316Z",
     "start_time": "2025-11-11T14:38:16.931246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "runner3 = ExpRunner.copy(runner1)\n",
    "runner3.exp_params = ExperimentConfig(test_size=0.5)\n",
    "runner3.run_experiment(runner3.build_data())"
   ],
   "id": "9bd1077d4ee6c95b",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ExperimentConfig.__init__() got an unexpected keyword argument 'TEST_SIZE'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[19]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m runner3 = ExpRunner.copy(runner1)\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m runner3.exp_params = \u001B[43mExperimentConfig\u001B[49m\u001B[43m(\u001B[49m\u001B[43mTEST_SIZE\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.5\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      3\u001B[39m runner3.run_experiment(runner3.build_data())\n",
      "\u001B[31mTypeError\u001B[39m: ExperimentConfig.__init__() got an unexpected keyword argument 'TEST_SIZE'"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fe416219b4d29bac"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
